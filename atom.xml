<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Unsky Blog</title>
  <subtitle>Unsky Blog</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2016-11-22T12:47:17.135Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>unsky</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>R-CNN-物体检测</title>
    <link href="http://yoursite.com/2016/11/22/R-CNN/"/>
    <id>http://yoursite.com/2016/11/22/R-CNN/</id>
    <published>2016-11-22T08:41:48.000Z</published>
    <updated>2016-11-22T12:47:17.135Z</updated>
    
    <content type="html"><![CDATA[<p>Rich feature hierarchies for accurate object detection and semantic segmentation是RBG大神的作品，提出了深度学习用于物体检测的开山之作r-cnn (Regions with Convolutional Neural Network Features)<br> <a id="more"></a></p>
<h1 id="IOU的定义"><a href="#IOU的定义" class="headerlink" title="IOU的定义"></a>IOU的定义</h1><p> 物体检测需要定位出物体的bounding box，就像下面的图片一样，我们不仅要定位出车辆的bounding box 我们还要识别出bounding box 里面的物体就是车辆。对于bounding box的定位精度，有一个很重要的概念，因为我们算法不可能百分百跟人工标注的数据完全匹配，因此就存在一个定位精度评价公式：IOU。</p>
<p> 矩形框A、B的一个重合度IOU计算公式为：</p>
<p> <img src="/images/r-cnn/1.png" alt=""><br> $$IOU=\left( A\cap B \right) /\left( A\cup B \right) $$<br> 就是矩形框A、B的重叠面积占A、B并集的面积比例:</p>
<h1 id="非极大值抑制"><a href="#非极大值抑制" class="headerlink" title="非极大值抑制"></a>非极大值抑制</h1><p>  <img src="/images/r-cnn/2.png" alt=""><br> 就像上面的图片一样，定位一个车辆，最后算法就找出了一堆的方框，我们需要判别哪些矩形框是没用的。非极大值抑制：先假设有6个矩形框，根据分类器类别分类概率做排序，从小到大分别属于车辆的概率分别为A、B、C、D、E、F。</p>
<ol>
<li><p>从最大概率矩形框F开始，分别判断A~E与F的重叠度IOU是否大于某个设定的阈值;</p>
</li>
<li><p>假设B、D与F的重叠度超过阈值，那么就扔掉B、D；并标记第一个矩形框F，是我们保留下来的。</p>
</li>
<li><p>从剩下的矩形框A、C、E中，选择概率最大的E，然后判断E与A、C的重叠度，重叠度大于一定的阈值，那么就扔掉；并标记E是我们保留下来的第二个矩形框。</p>
</li>
</ol>
<p>就这样一直重复，找到所有被保留下来的矩形框。</p>
<h1 id="r-cnn的论文思想"><a href="#r-cnn的论文思想" class="headerlink" title="r-cnn的论文思想"></a>r-cnn的论文思想</h1><p> <img src="/images/r-cnn/3.png" alt=""><br> 在如今看来是非常简单的，</p>
<ol>
<li>首先在原图中使用selective_search进行窗口的推荐推荐出2000个候选窗口。</li>
<li><p>然后采用CNN提取每个候选框中图片的特征向量，特征向量的维度为4096维。</p>
</li>
<li><p>接着采用svm算法对各个候选框中的物体进行分类识别</p>
<h1 id="部分实现细节"><a href="#部分实现细节" class="headerlink" title="部分实现细节"></a>部分实现细节</h1><h2 id="selective-search"><a href="#selective-search" class="headerlink" title="selective_search"></a>selective_search</h2><p>当我们输入一张图片时，我们要搜索出所有可能是物体的区域，这个采用的方法是传统文献的算法：《search for object recognition》，通过这个算法我们搜索出2000个候选框。然后从上面的总流程图中可以看到，搜出的候选框是矩形的，而且是大小各不相同。然而CNN对输入图片的大小是有固定的，如果把搜索到的矩形选框不做处理，就扔进CNN中，肯定不行。因此对于每个输入的候选框都需要缩放到固定的大小。下面我们讲解要怎么进行缩放处理，为了简单起见我们假设下一阶段CNN所需要的输入图片大小是个正方形图片227*227。因为我们经过selective search 得到的是矩形框，paper试验了两种不同的处理方法：<br><img src="/images/r-cnn/4.png" alt=""></p>
</li>
<li>各向异性缩放,这种方法很简单，就是不管图片的长宽比例，管它是否扭曲，进行缩放就是了，全部缩放到CNN输入的大小227*227，如下图(D)所示；</li>
<li>先把bounding box图片裁剪出来，然后用固定的背景颜色填充成正方形图片(背景颜色也是采用bounding box的像素颜色均值),如下图(C)所示;</li>
</ol>
<p>对于上面的异性、同性缩放，文献还有个padding处理，上面的示意图中第1、3行就是结合了padding=0,第2、4行结果图采用padding=16的结果。经过最后的试验，作者发现采用各向异性缩放、padding=16的精度最高.</p>
<h2 id="fine-tuning阶段"><a href="#fine-tuning阶段" class="headerlink" title="fine-tuning阶段"></a>fine-tuning阶段</h2><p>我们接着采用selective search 搜索出来的候选框，然后处理到指定大小图片，继续对上面预训练的cnn模型进行fine-tuning训练。假设要检测的物体类别有N类，那么我们就需要把上面预训练阶段的CNN模型的最后一层给替换掉，替换成N+1个输出的神经元(加1，表示还有一个背景)，然后这一层直接采用参数随机初始化的方法，其它网络层的参数不变；接着就可以开始继续SGD训练了。开始的时候，SGD学习率选择0.001，在每次训练的时候，我们batch size大小选择128，其中32个正样本、96个负样本(1:3)<br>note：作者在此论文中给出了卷积层和全连接层的一些特征，拿vgg16而言，网络的卷积层部分可以看作是sift等一样的特征提取器，但是对于全连接层是根据特定任务而言的，比如vgg16是用于图片分类，我们可以直接用其卷积层进行特征提取，而对于全连接，一般需要针对人脸任务进行一部分的微调。</p>
<p><code>一些附加的调参技巧：在cat vs dog 的二分类竞赛中，发现对于vgg16网络，如果仅仅改变全连接层，那么效果可以达到正确率95%,但是如果微调vgg16的conv5+全连接层可以达到正确率98%</code></p>
<h1 id="实验效果"><a href="#实验效果" class="headerlink" title="实验效果"></a>实验效果</h1><p> <img src="/images/r-cnn/5.png" alt=""></p>
<p>具体的实验代码可以在<br><a href="https://github.com/unsky/rcnn" target="_blank" rel="external">https://github.com/unsky/rcnn</a><br>中找到。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Rich feature hierarchies for accurate object detection and semantic segmentation是RBG大神的作品，提出了深度学习用于物体检测的开山之作r-cnn (Regions with Convolutional Neural Network Features)&lt;br&gt;
    
    </summary>
    
      <category term="卷积深度网络" scheme="http://yoursite.com/categories/%E5%8D%B7%E7%A7%AF%E6%B7%B1%E5%BA%A6%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="R-CNN" scheme="http://yoursite.com/tags/R-CNN/"/>
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="物体检测" scheme="http://yoursite.com/tags/%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>深度学习总结</title>
    <link href="http://yoursite.com/2016/11/22/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    <id>http://yoursite.com/2016/11/22/深度学习总结/</id>
    <published>2016-11-22T01:59:27.000Z</published>
    <updated>2016-11-22T08:42:34.294Z</updated>
    
    <content type="html"><![CDATA[<p>读过的文章比较杂，在应用方面的比较少，涉及结构和基础理论的比较多。。<br>刚开始看深度学习的文章对激活函数不是很懂，所以找了相关的文章<br>Rectified Linear Units Improve Restricted Boltzmann Machines 这篇论文是ReLU激活函数的提出，它根据脑部信号的激活展开了讨论，最后认为ReLU函数可以很好的拟合这种激活信号并且，具有保持一定的稀疏性。</p>
<p>VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION<br>这篇论文提出了VGG16的网络结构用于图像分类，是非常经典的结构。</p>
<p>对于传统的神经网络，因为全连接层的限制所以必须输入固定大小的图片，所以必须对每个图片预处理进行resize成固定大小，但是这样做会对一些小尺寸和大尺寸的图片产生影响从而影响正确率。正好空间金字塔有一个好处就是可以将任意尺寸的都max-pool成固定大小的，所以<br>Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition 的提出也是很必然的。</p>
<p>在传统的深度学习中，层与层之间是用非线性函数激活的，所以他们之间是非线性联合的，这保证了它的深度，但是用很多层的非线性联合来组成一个神经网络和只用很少的层但用每个层之间用更强的非线性进行联合效果会怎么样?所以作者在 Network In Network这篇论文中提出了一种网中网的结构，就是以前的时候层与层直接只要一个非线性激活函数激活就行了，但是因为多层感知机的非线性据我们所知是很强的，所以作者将每个传统的层之间用多层感知机进行激活。来达到非线性联合的目的，在试验中它指出他仅仅用三层的结构就达到了ALexnet五层的效果。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;读过的文章比较杂，在应用方面的比较少，涉及结构和基础理论的比较多。。&lt;br&gt;刚开始看深度学习的文章对激活函数不是很懂，所以找了相关的文章&lt;br&gt;Rectified Linear Units Improve Restricted Boltzmann Machines 这篇论文
    
    </summary>
    
      <category term="深度学习" scheme="http://yoursite.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>String to Integer (atoi) 字符转int类型</title>
    <link href="http://yoursite.com/2016/11/21/String-to-Integer-atoi-%E5%AD%97%E7%AC%A6%E8%BD%ACint%E7%B1%BB%E5%9E%8B/"/>
    <id>http://yoursite.com/2016/11/21/String-to-Integer-atoi-字符转int类型/</id>
    <published>2016-11-21T13:45:58.000Z</published>
    <updated>2016-11-21T14:53:33.912Z</updated>
    
    <content type="html"><![CDATA[<p>id8:String to Integer (atoi)   QuestionEditorial Solution  My Submissions<br>Total Accepted: 136242<br>Total Submissions: 989232<br>Difficulty: Easy<br>Contributors: Admin<br>Implement atoi to convert a string to an integer.<br> <a id="more"></a></p>
<p>Hint: Carefully consider all possible input cases. If you want a challenge, please do not see below and ask yourself what are the possible input cases.</p>
<p>Notes: It is intended for this problem to be specified vaguely (ie, no given input specs). You are responsible to gather all the input requirements up front.</p>
<p>Update (2015-02-10):<br>The signature of the C++ function had been updated. If you still see your function signature accepts a const char * argument, please click the reload button  to reset your code definition.<br>Requirements for atoi:<br>The function first discards as many whitespace characters as necessary until the first non-whitespace character is found. Then, starting from this character, takes an optional initial plus or minus sign followed by as many numerical digits as possible, and interprets them as a numerical value.</p>
<p>The string can contain additional characters after those that form the integral number, which are ignored and have no effect on the behavior of this function.</p>
<p>If the first sequence of non-whitespace characters in str is not a valid integral number, or if no such sequence exists because either str is empty or it contains only whitespace characters, no conversion is performed.</p>
<p>If no valid conversion could be performed, a zero value is returned. If the correct value is out of the range of representable values, INT_MAX (2147483647) or INT_MIN (-2147483648) is returned.</p>
<p>这道题目正常的转换非常简单，比较麻烦的就是处理边界问题，在测试集里面需要考虑如下集中边界问题：</p>
<ol>
<li>起始和结束空格问题如 <code>&quot;.&quot;</code> return 0;和 <code>&quot;....-48755....&quot;</code> return -48755, 其中 <code>&quot;.&quot;</code> 表示空格，</li>
<li>去掉问题1后的符号字符问题，比如 <code>+8975</code> return 8975, <code>89454</code> return 89484,<code>-8975</code> return -8975, 即必须提取出合适的正负号.其中正号可以省略。</li>
<li>去掉1和2问题后的结束字符问题，如，<code>8986jhuuh</code> return 8986.</li>
<li><p>溢出问题，写此文章时2016/11/21，leetcode已经在此测试集中加入了对long long的溢出判断。所以不能使用long long 类型进行溢出判断。可以使用<br><a href="http://deepdim.com/2016/11/21/Reverse-Integer-%E9%80%86%E7%BD%AEint%E6%95%B0/#more" target="_blank" rel="external">http://deepdim.com/2016/11/21/Reverse-Integer-%E9%80%86%E7%BD%AEint%E6%95%B0/#more</a><br>中的溢出方法，即：<code>使用前一个结果得标志</code> 在溢出得时候只有每次乘以10的时候会产生溢出，假设没乘以10之前的结果保存在pre_result,在乘以10之后的结果为 result,可以使用<code>result/10!=pre_result</code>来进行溢出判断，因为如果溢出结果就是一个溢出的数字不满足乘以10的结果</p>
<p>note: 测试集中存在测试字符串 <code>+-8968</code>,在去掉1和2问题之后变为’-8968’等同于<code>&quot;.&quot;</code>,所以return 0,如果不好理解，可以将问题放大：如<code>-895-775</code>在去掉问题1和2的影响后，等同于<code>895</code>所以return 895.</p>
</li>
</ol>
<p>程序代码如下：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">myAtoi</span><span class="params">(<span class="built_in">string</span> str)</span> </span>&#123;</div><div class="line">        str.erase(<span class="number">0</span>,str.find_first_not_of(<span class="string">' '</span>));</div><div class="line">        str.erase(str.find_last_not_of(<span class="string">' '</span>)+<span class="number">1</span>);</div><div class="line">        <span class="keyword">int</span> result=<span class="number">0</span>;</div><div class="line">        <span class="keyword">int</span> pre_result;</div><div class="line">        <span class="keyword">int</span> sigm=<span class="number">1</span>;</div><div class="line">        <span class="keyword">if</span>(str[<span class="number">0</span>]==<span class="string">'-'</span>)</div><div class="line">        &#123;sigm=<span class="number">-1</span>;</div><div class="line">            str=str.substr(<span class="number">1</span>);</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(str[<span class="number">0</span>]==<span class="string">'+'</span>)</div><div class="line">       str=str.substr(<span class="number">1</span>);</div><div class="line"></div><div class="line">       <span class="keyword">if</span> (str.length()==<span class="number">0</span>)<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;str.length();i++)</div><div class="line">        &#123;<span class="keyword">if</span>(str[i]&lt;<span class="string">'0'</span>||str[i]&gt;<span class="string">'9'</span>)</div><div class="line">         <span class="keyword">break</span>;</div><div class="line">         pre_result=result;</div><div class="line">         result=result*<span class="number">10</span>+str[i]<span class="number">-48</span>;</div><div class="line">         <span class="keyword">if</span>(result/<span class="number">10</span>!=pre_result)<span class="comment">//溢出操作，注意在测试数据集里 Long long 类型也溢出</span></div><div class="line">         &#123;   <span class="keyword">if</span>(sigm&lt;<span class="number">0</span>)<span class="keyword">return</span> INT_MIN;</div><div class="line">             <span class="keyword">else</span> <span class="keyword">return</span> INT_MAX;</div><div class="line">         &#125;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        <span class="keyword">return</span> (sigm*result);</div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>本地测试用例：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;string&gt;</span></span></div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</div><div class="line"><span class="keyword">int</span> INT_MIN=<span class="number">-2147483648</span>;</div><div class="line"><span class="keyword">int</span> INT_MAX=<span class="number">2147483647</span>;</div><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">myAtoi</span><span class="params">(<span class="built_in">string</span> str)</span> </span>&#123;</div><div class="line">        str.erase(<span class="number">0</span>,str.find_first_not_of(<span class="string">' '</span>));</div><div class="line">        str.erase(str.find_last_not_of(<span class="string">' '</span>)+<span class="number">1</span>);</div><div class="line">        <span class="keyword">int</span> result=<span class="number">0</span>;</div><div class="line">        <span class="keyword">int</span> pre_result;</div><div class="line">        <span class="keyword">int</span> sigm=<span class="number">1</span>;</div><div class="line">        <span class="keyword">if</span>(str[<span class="number">0</span>]==<span class="string">'-'</span>)</div><div class="line">        &#123;sigm=<span class="number">-1</span>;</div><div class="line">            str=str.substr(<span class="number">1</span>);</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(str[<span class="number">0</span>]==<span class="string">'+'</span>)</div><div class="line">       str=str.substr(<span class="number">1</span>);</div><div class="line">       <span class="keyword">if</span> (str.length()==<span class="number">0</span>)<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;str.length();i++)</div><div class="line">        &#123;<span class="keyword">if</span>(str[i]&lt;<span class="string">'0'</span>||str[i]&gt;<span class="string">'9'</span>)</div><div class="line">         <span class="keyword">break</span>;</div><div class="line">         pre_result=result;</div><div class="line">         result=result*<span class="number">10</span>+str[i]<span class="number">-48</span>;</div><div class="line">         <span class="keyword">if</span>(result/<span class="number">10</span>!=pre_result)<span class="comment">//溢出操作，注意在测试数据集里 Long long 类型也溢出</span></div><div class="line">         &#123;   <span class="keyword">if</span>(sigm&lt;<span class="number">0</span>)<span class="keyword">return</span> INT_MIN;</div><div class="line">             <span class="keyword">else</span> <span class="keyword">return</span> INT_MAX;</div><div class="line">         &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> (sigm*result);</div><div class="line">    &#125;</div><div class="line">&#125;;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></div><div class="line">&#123; <span class="built_in">string</span> str;</div><div class="line">  <span class="built_in">cin</span>&gt;&gt;str;</div><div class="line">  Solution so;</div><div class="line">  <span class="built_in">cout</span>&lt;&lt;so.myAtoi(str);</div><div class="line">  <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;id8:String to Integer (atoi)   QuestionEditorial Solution  My Submissions&lt;br&gt;Total Accepted: 136242&lt;br&gt;Total Submissions: 989232&lt;br&gt;Difficulty: Easy&lt;br&gt;Contributors: Admin&lt;br&gt;Implement atoi to convert a string to an integer.&lt;br&gt;
    
    </summary>
    
      <category term="leetcode" scheme="http://yoursite.com/categories/leetcode/"/>
    
    
      <category term="String to Integer" scheme="http://yoursite.com/tags/String-to-Integer/"/>
    
  </entry>
  
  <entry>
    <title>Reverse Integer 逆置int数</title>
    <link href="http://yoursite.com/2016/11/21/Reverse-Integer-%E9%80%86%E7%BD%AEint%E6%95%B0/"/>
    <id>http://yoursite.com/2016/11/21/Reverse-Integer-逆置int数/</id>
    <published>2016-11-21T02:59:05.000Z</published>
    <updated>2016-11-21T03:20:16.983Z</updated>
    
    <content type="html"><![CDATA[<p>id7. Reverse Integer   QuestionEditorial Solution  My Submissions<br>Total Accepted: 185981<br>Total Submissions: 785209<br>Difficulty: Easy<br>Contributors: Admin<br>Reverse digits of an integer.<br>Example1: x = 123, return 321<br>Example2: x = -123, return -321<br> <a id="more"></a><br>Have you thought about this?<br>Here are some good questions to ask before coding. Bonus points for you if you have already thought through this!</p>
<p>If the integer’s last digit is 0, what should the output be? ie, cases such as 10, 100.</p>
<p>Did you notice that the reversed integer might overflow? Assume the input is a 32-bit integer, then the reverse of 1000000003 overflows. How should you handle such cases?</p>
<p>For the purpose of this problem, assume that your function returns 0 when the reversed integer overflows.<br>Update (2014-11-10):<br>Test cases had been added to test the overflow behavior.</p>
<p>这个题目非常简单，唯一比较麻烦得是判断溢出。</p>
<p>“leetcode判断溢出得方法”</p>
<ol>
<li><code>设置最大最小2147483647 ~ -2147483648</code> 在本地环境下没有问题，但是leetcode就不行了，编译环境得问题。</li>
<li><code>使用前一个结果得标志</code> 在溢出得时候只有每次乘以10的时候会产生溢出，假设没乘以10之前的结果保存在pre_result,在乘以10之后的结果为 result,可以使用<code>result/10!=pre_result</code>来进行溢出判断，因为如果溢出结果就是一个溢出的数字不满足乘以10的结果。</li>
</ol>
<p>比较啰嗦的借助了一个vector实现：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">reverse</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</div><div class="line">        <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vec;</div><div class="line">        <span class="keyword">int</span> num;</div><div class="line">        <span class="keyword">int</span> pre_result=<span class="number">0</span>;</div><div class="line">        <span class="keyword">int</span> result=<span class="number">0</span>;</div><div class="line">        <span class="keyword">int</span> flag=<span class="number">1</span>;</div><div class="line">        <span class="keyword">if</span> (x&lt;=<span class="number">0</span>)&#123;</div><div class="line">        num=<span class="number">-1</span>*x;</div><div class="line">         flag=<span class="number">-1</span>;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">if</span>(x&gt;<span class="number">0</span>)</div><div class="line">        num=x;</div><div class="line">        <span class="built_in">cout</span>&lt;&lt;num;</div><div class="line">     <span class="keyword">while</span>(num)</div><div class="line">     &#123;vec.push_back(num%<span class="number">10</span>);</div><div class="line">     num=num/<span class="number">10</span>;</div><div class="line">     &#125;</div><div class="line">     <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;::iterator it=vec.begin();</div><div class="line">     <span class="keyword">for</span>(;it!=vec.end();it++)</div><div class="line">     &#123;    pre_result=result;</div><div class="line">         result=result*<span class="number">10</span>+(*it);</div><div class="line">         <span class="keyword">if</span> (result/<span class="number">10</span>!=pre_result)</div><div class="line">         <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">     &#125;</div><div class="line">     <span class="keyword">return</span> flag*result;</div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>精简版，不借助容器实现：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="keyword">int</span> <span class="title">reverse</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> pre_result=<span class="number">0</span>;</div><div class="line">    <span class="keyword">int</span> result=<span class="number">0</span>;</div><div class="line">    <span class="keyword">while</span>(x)</div><div class="line">    &#123;pre_result=result;</div><div class="line">    result=result*<span class="number">10</span>+x%<span class="number">10</span>;</div><div class="line">    x=x/<span class="number">10</span>;</div><div class="line">    <span class="keyword">if</span>(result/<span class="number">10</span>!=pre_result)</div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">     &#125;</div><div class="line">     <span class="keyword">return</span> result;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;id7. Reverse Integer   QuestionEditorial Solution  My Submissions&lt;br&gt;Total Accepted: 185981&lt;br&gt;Total Submissions: 785209&lt;br&gt;Difficulty: Easy&lt;br&gt;Contributors: Admin&lt;br&gt;Reverse digits of an integer.&lt;br&gt;Example1: x = 123, return 321&lt;br&gt;Example2: x = -123, return -321&lt;br&gt;
    
    </summary>
    
      <category term="leetcode" scheme="http://yoursite.com/categories/leetcode/"/>
    
    
      <category term="Reverse Integer" scheme="http://yoursite.com/tags/Reverse-Integer/"/>
    
  </entry>
  
  <entry>
    <title>回声状态网络ESN</title>
    <link href="http://yoursite.com/2016/11/18/%E5%9B%9E%E5%A3%B0%E7%8A%B6%E6%80%81%E7%BD%91%E7%BB%9CESN/"/>
    <id>http://yoursite.com/2016/11/18/回声状态网络ESN/</id>
    <published>2016-11-18T11:32:31.000Z</published>
    <updated>2016-11-19T04:26:49.646Z</updated>
    
    <content type="html"><![CDATA[<p><code>ESN( echo state networks)</code>:<br>针对递归神经网络训练困难以及记忆渐消问题,jaeger 于2001年提出一种新型递归神经网络— — —回声状态网络. ESN网络一经提出便成为学术界的研究热点，并应用到各种不同领域，包括动态模式分类、机器人控制、对象跟踪核运动目标 检 测、 事 件 监 测 等， 尤其是时间序列预测问题.<br> <a id="more"></a></p>
<h1 id="ESN"><a href="#ESN" class="headerlink" title="ESN"></a>ESN</h1><p>ESN 属于RNN的范畴，具有短期记忆的能力。今天将探讨和实验ESN在时间序列问题上的原理。</p>
<p>时间序列数据往往具有高噪声、随机性以及非线性等特点，其建模、分析以及预测问题一直是学术界研究的热点 ．一般地讲，为了更加准确地预测时间序列，需要时间序列模型既具有良好的非线性逼近能力，又具有良好的记忆能力 ．这对于经典的时间序列建模和分析方法提出极大的挑战 ．为了解决非线性时间序列预测问题，支持向量机、神经网络等人工智能方法被引入到时间序列分析领域.</p>
<h1 id="ESN结构"><a href="#ESN结构" class="headerlink" title="ESN结构"></a>ESN结构</h1><p> 相对于传统神经网络结构ESN所学习的并不是神经元的权重，二是神经元之间的链接。<br> 回声状态状态网络作为一种新型的递归神经网络，无论是建模还是学习算法，都已经与传统的递归神经网络差别很大。<br> 比较直观的结构如下：<br><img src="/images/esn/1.png" alt=""></p>
<h2 id="ESN网络特点："><a href="#ESN网络特点：" class="headerlink" title="ESN网络特点："></a>ESN网络特点：</h2><ol>
<li>它的核心结构是一个随机生成、且保持不 变的储备池（Reservoir）</li>
<li>其输出权值是唯一需要调整的部分</li>
<li>简单的线性回归就可完成网络的训练<h1 id="ESN的数学模型"><a href="#ESN的数学模型" class="headerlink" title="ESN的数学模型"></a>ESN的数学模型</h1></li>
</ol>
<p>假设系统具有M个输入单元,N个内部处理单元（Processing elements PEs），即N个内部神经元,同时具有L个输出单元,输入单元、内部状态、以及输出单元n时刻的值分别为<br><img src="/images/esn/2.png" alt=""></p>
<p>$$u\left( n \right) =\left[ u_1\left( n \right) ,…,u_M\left( n \right) \right] ^T$$<br>$$x\left( n \right) =\left[ x_1\left( n \right) ,…,x_N\left( n \right) \right] ^T$$<br>$$y\left( n \right) =\left[ y_1\left( n \right) ,…,y_L\left( n \right) \right] ^T$$<br>其中，$u\left( n \right) \in R^{K\times 1}$ , $x\left( n \right) \in R^{N\times 1}$ , $y\left( n \right) \in R^{L\times 1}$</p>
<p>从结构上讲，ESNs是一种特殊类型的神经网络，其基本思想是使用大规模随机连接的递归网络，取代经典神经网络中的中间层，从而简化网络的训练过程,回声状态网络的状态方程为：<br>$$x\left( n+1 \right) =f\left( Wx\left( n \right) +W^{in}u\left( n \right) +W^{back}y\left( n \right) \right) $$<br>$$<br>y\left( n+1 \right) =f_{out}\left( W^{out}\left[ x\left( n+1 \right) ,u\left( n+1 \right) ,y\left( n \right) \right] +b^{out} \right)$$</p>
<p>其中，$W\in R^{N\times N}$ , $W^{in}\in R^{N\times K}$ , $W^{back}\in R^{N\times L}$ , $W^{out}\in R^{\left( L+K+N \right) \times L}$</p>
<p>f为激活函数，一般为双曲正切函数。<br>其中W, $W^{in}$ , $W^{back}$ 分别表示状态变量、输入和输出对状态变量的连接权矩阵；$W^{out}$ 表示储备池、输入和输出对于输出的连接权矩阵，$b^{out}$ 表示输出的偏置项或者可以代表噪声,表示内部神经元激活函数,在网络训练过程中，连接到储备池的连接权矩阵 W, $W^{in}$ , $W^{back}$ 随机产生,一经产生就固定不变.而连接到输出的连接权矩阵 $W^{out}$ 需要通过训练得到，因为状态变量、输入和输出与输出之间是线性关系，所以通常这些连接权只需通过求解线性回归问题得到。</p>
<h1 id="ESN的训练"><a href="#ESN的训练" class="headerlink" title="ESN的训练"></a>ESN的训练</h1><p>ESNs的训练过程就是根据给定的训练样本 $u\left( n \right) =\left[ u_1\left( n \right) ,…,u_M\left( n \right) \right] ^T$ ，确定系统输出连接权矩阵<br> $W^{out}$的过程 ．<br>ESNs的训练分为两个过程： <code>采样过程</code>和<code>权值计算过程</code></p>
<h2 id="采样过程"><a href="#采样过程" class="headerlink" title="采样过程"></a>采样过程</h2><p>采样阶段首先任意选定网络的初始状态，但是通常情况下选取网络的初始状态为0，即 $x(0)=0$ ,训练样本$u\left( n \right) =\left[ u_1\left( n \right) ,…,u_M\left( n \right) \right] ^T$ 经过输入连接权矩阵 $W^{in}$ 被加入到储备池中， 按照方程，依次完成系统状态和输出珋 $y(n)$ 的计算与收集 ． 为了计算输出连接权矩阵，需要从某一时刻 m 开始收集（采样）内部状态变量，并以向量 $x\left( n \right) =\left[ x_1\left( n \right) ,…,x_N\left( n \right) \right] ^T$ 为行构成矩阵，同时相应的样本数据 y(n)也被收集，并构成一个列向量  $B\in R^{\left( p-m+1 \right) \times N}$ ,同时相应的样本数据y(n)也被收集，并构成 $T\in R^{\left( p-m+1 \right) \times L}$</p>
<h2 id="权值计算"><a href="#权值计算" class="headerlink" title="权值计算"></a>权值计算</h2><p>权值计算就是根据在采样阶段收集到系统状态矩阵和样本数据，计算输出连接权  $W^{out}$ ． 因为状态变量 $x(n)$ 和系统输出 $y(n)$ 之间是线性关系，而需要实现的目标是利用网络实际输出逼近期望输出 :<br>$$y\left( n \right) \approx \hat{y}\left( n \right) =\sum_{i=1}^L{w_{i}^{out}x_i\left( n \right)}$$</p>
<p>所以损失函数为：<br>$$\underset{w_{i}^{out}}{\min}\frac{1}{p-m+1}\sum_{n=m}^P{\left( y\left( n \right) -\sum_{i=1}^L{w_{i}^{out}x_i\left( n \right)} \right) ^2}$$</p>
<p>所以其训练过程可以用于计算：<br>$$W^{out}=B^{-1}T $$</p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>实验代码：<a href="https://github.com/unsky/esn-rmlp" target="_blank" rel="external">https://github.com/unsky/esn-rmlp</a></p>
<h2 id="主程序"><a href="#主程序" class="headerlink" title="主程序"></a>主程序</h2><p><code>esn_main.m</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">clear;</div><div class="line">clc;</div><div class="line">% Generate ESN for training</div><div class="line">net = esn_net(25, 600, 1);</div><div class="line">% Generate training data</div><div class="line">[I_data, T_data] = seq_gen_esn(26);</div><div class="line">% Train ESN</div><div class="line">net_trained = esn_train(net,I_data,T_data);</div><div class="line"></div><div class="line">% Test ESN</div><div class="line">[original_out,net_out,error] = esn_test(net_trained);</div></pre></td></tr></table></figure></p>
<h2 id="训练数据准备"><a href="#训练数据准备" class="headerlink" title="训练数据准备"></a>训练数据准备</h2><p>　<code>seq_gen_esn</code> 用于产生3000个训练数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">t = 0 : 3000;                      % training sequence time interval</div><div class="line">y = signal(t);                     % generate training sequence</div><div class="line">len = length(y);</div><div class="line">incom_data = (rand(1,len)&gt;0.00);   % incomplete data ratio</div><div class="line">y = y.*incom_data;</div><div class="line">num_subset = len - len_subset + 1; % number of subset</div><div class="line">fprintf(&apos;Training sequence generation is in process, please wait...\n&apos;)</div><div class="line">%&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Main Loop &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</div><div class="line">for i = (1:num_subset),</div><div class="line">    I_data(i,:) = y(i:len_subset-2+i);</div><div class="line">    T_data(i,:) = y(len_subset-1+i);</div><div class="line">end;</div></pre></td></tr></table></figure></p>
<h2 id="网络训练"><a href="#网络训练" class="headerlink" title="网络训练"></a>网络训练</h2><p><code>esn_train</code>用于网络训练求得 $W^{out}$</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div></pre></td><td class="code"><pre><div class="line">AUC  = net.numAllUnits;           % number of all units</div><div class="line">IUC  = net.numInputUnits;         % number of input units</div><div class="line">OUC  = net.numOutputUnits;        % number of output units</div><div class="line">HUC  = net.numHiddenLayer;        % number of hidden units</div><div class="line">drWeights = net.reservoirWeights; % dynamic reservoir weights matrix</div><div class="line">inWeights = net.inputWeights;     % input matrix</div><div class="line">bkWeights = net.backWeights;      % backward weights from output layer</div><div class="line">ouWeights = net.outputWeights;    % output weights matrix</div><div class="line">bl_out    = net.bl_out;           % type of output neuron</div><div class="line">int_bk    = net.int_bk;           % intensity of feedback</div><div class="line">attenu    = net.attenu;           % attenuation ratio for the signal</div><div class="line"></div><div class="line">%&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Parameter Check &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</div><div class="line">[inpSize, inpNum] = size(I_data&apos;);</div><div class="line">[tarSize, tarNum] = size(T_data&apos;);</div><div class="line">if inpSize ~= IUC,</div><div class="line">    error (&apos;Number of input units and input pattern size do not match.&apos;);</div><div class="line">end;</div><div class="line">if tarSize ~= OUC,</div><div class="line">    error (&apos;Number of output units and target pattern size do not match.&apos;);</div><div class="line">end;</div><div class="line">if inpNum ~= tarNum,</div><div class="line">    error (&apos;Number of input and output patterns are different.&apos;);</div><div class="line">end;</div><div class="line"></div><div class="line">%&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;  Initialization of Training &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</div><div class="line">I_data  = attenu*I_data;</div><div class="line">T_data  = attenu*T_data;</div><div class="line">X(1,:)  = zeros(1,HUC);               % initial reservoir state</div><div class="line">I1_data = [zeros(1,inpSize); I_data]; % add zero to initial input</div><div class="line">T1_data = [zeros(1,tarSize); T_data]; % add zero to initial output</div><div class="line">timeflag= cputime;                    % a timer to save the training time</div><div class="line">wb = waitbar(0, &apos;Echo State Network Training in Progress...&apos;);</div><div class="line">T0 = 1000;                            % washout time</div><div class="line">fprintf(&apos;\nThe echo state network training is in process...\n&apos;);</div><div class="line"></div><div class="line">%&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Main Loop of ESN Training &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</div><div class="line">for i = (1:inpNum),</div><div class="line">    waitbar(i/inpNum,wb)</div><div class="line">    set(wb,&apos;name&apos;,[&apos;Progress = &apos; sprintf(&apos;%2.1f&apos;,i/inpNum*100) &apos;%&apos;]);</div><div class="line">    X(i+1,:) = hyperb((inWeights*I1_data(i+1,:)&apos; + drWeights*X(i,:)&apos; + ...</div><div class="line">                int_bk*bkWeights*T1_data(i,:)&apos; + 0.001*(rand(1,HUC)-0.5)&apos;)&apos;);</div><div class="line">end;</div><div class="line">close(wb);</div><div class="line">fprintf(&apos;Please wait for another while...\n&apos;);</div><div class="line"></div><div class="line">%&gt;&gt;&gt;&gt;&gt;&gt; Calculate output weights and update ESN &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</div><div class="line">if (bl_out == 1),</div><div class="line">    ouWeights = (pinv(X(T0+2:end,:))*(T_data(T0+1:end,:)))&apos;; % linear output</div><div class="line">else</div><div class="line">    ouWeights = (pinv(X(T0+2:end,:))*(inv_hyperb(T_data(T0+1:end,:))))&apos;;</div><div class="line">end;</div><div class="line">net.outputWeights = ouWeights;</div><div class="line">net_trained       = net;</div><div class="line">timeflag          = cputime - timeflag;</div><div class="line">fprintf(&apos;Training accomplished! Total time is %2.2f hours.\n&apos;,timeflag/3600);</div></pre></td></tr></table></figure>
<h2 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h2><p><code>esn_test</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div></pre></td><td class="code"><pre><div class="line">%&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Obtain parameters from RMLP net &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</div><div class="line">AUC  = net.numAllUnits;           % number of all units</div><div class="line">IUC  = net.numInputUnits;         % number of input units</div><div class="line">OUC  = net.numOutputUnits;        % number of output units</div><div class="line">HUC  = net.numHiddenLayer;        % number of hidden units</div><div class="line">drWeights = net.reservoirWeights; % dynamic reservoir weights matrix</div><div class="line">inWeights = net.inputWeights;     % input matrix</div><div class="line">bkWeights = net.backWeights;      % backward weights from output layer</div><div class="line">ouWeights = net.outputWeights;    % output weights matrix</div><div class="line">len_subset= IUC + OUC;            % subset length</div><div class="line">bl_out    = net.bl_out;           % type of output neuron</div><div class="line">int_bk    = net.int_bk;           % intensity of feedback</div><div class="line">attenu    = net.attenu;           % attenuation ratio for the signal</div><div class="line"></div><div class="line">%&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Testing Parameters Setting &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</div><div class="line">S_point = 4000;            % starting point of testing data</div><div class="line">testNum = 3000;            % number of testing data</div><div class="line">X(1,:)  = zeros(1,HUC);    % initial reservoir state</div><div class="line">t       = [S_point : S_point+len_subset-1];</div><div class="line">y0      = rand(1,OUC)-0.5; % initial output</div><div class="line"></div><div class="line">%&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Check parameter &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</div><div class="line">if length(t) ~= len_subset,</div><div class="line">    error(&apos;Length of testing data subset and the network structure do not match&apos;);</div><div class="line">end;</div><div class="line"></div><div class="line">%&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Testing Main Routine &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</div><div class="line">wb = waitbar(0, &apos;Echo State Network Testing in Progress...&apos;);</div><div class="line">for i = (1:testNum),</div><div class="line">    waitbar(i/testNum,wb)</div><div class="line">    set(wb,&apos;name&apos;,[&apos;Progress = &apos; sprintf(&apos;%2.1f&apos;,i/testNum*100) &apos;%&apos;]);</div><div class="line">    y = attenu*signal(t);                                   % generate testing data</div><div class="line">    X(i+1,:) = hyperb((inWeights*y(1:end-OUC)&apos; + ...</div><div class="line">               drWeights*X(i,:)&apos; + int_bk*bkWeights*y0&apos;)&apos;); % update reservoir state</div><div class="line">    if (bl_out == 1),</div><div class="line">        Y(i+1,:) = ouWeights*X(i+1,:)&apos;;        % update output state - Linear output</div><div class="line">    else</div><div class="line">        Y(i+1,:) = hyperb(ouWeights*X(i+1,:)&apos;);  % update output state - nonlinear output</div><div class="line">    end;</div><div class="line"></div><div class="line">    % update state for next iteration and output</div><div class="line">    original_out(i) = (1/attenu)*y(end-OUC+1:end);   % original output</div><div class="line">    net_out(i)      = (1/attenu)*Y(i+1,:);           % network output</div><div class="line">    error(i)        = net_out(i) - original_out(i);  % errors</div><div class="line">    y0 = Y(i+1,:);                                   % store the output for next calculation</div><div class="line">    t  = t + 1;                                      % Move one-step forward</div><div class="line">end;</div><div class="line">close(wb);</div><div class="line"></div><div class="line">%&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Plotting &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;</div><div class="line">subplot(211);</div><div class="line">plot([S_point+1:S_point+testNum],original_out,&apos;b&apos;,[S_point+1:S_point+testNum],net_out,&apos;r&apos;);</div><div class="line">hold on; grid on;</div><div class="line">legend(&apos;Original sequence&apos;,&apos;Network output&apos;);</div><div class="line">xlabel(&apos;time&apos;); ylabel(&apos;Amplitude&apos;);</div><div class="line">subplot(212);</div><div class="line">plot([S_point+1:S_point+testNum],error,&apos;b&apos;);</div><div class="line">hold on; grid on;</div><div class="line">xlabel(&apos;Time&apos;); ylabel(&apos;Output error&apos;);</div><div class="line">RMSE = sqrt(mean((net_out(1:end) - original_out(1:end)).^2))</div></pre></td></tr></table></figure></p>
<h1 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h1><p><img src="/images/esn/3.png" alt=""><br>从错误率可以看出，ESNs的误差率可以接受。。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;ESN( echo state networks)&lt;/code&gt;:&lt;br&gt;针对递归神经网络训练困难以及记忆渐消问题,jaeger 于2001年提出一种新型递归神经网络— — —回声状态网络. ESN网络一经提出便成为学术界的研究热点，并应用到各种不同领域，包括动态模式分类、机器人控制、对象跟踪核运动目标 检 测、 事 件 监 测 等， 尤其是时间序列预测问题.&lt;br&gt;
    
    </summary>
    
      <category term="时间序列" scheme="http://yoursite.com/categories/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    
    
      <category term="回声状态网络" scheme="http://yoursite.com/tags/%E5%9B%9E%E5%A3%B0%E7%8A%B6%E6%80%81%E7%BD%91%E7%BB%9C/"/>
    
      <category term="时间序列" scheme="http://yoursite.com/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    
      <category term="RNN" scheme="http://yoursite.com/tags/RNN/"/>
    
  </entry>
  
  <entry>
    <title>fast-r-cnn-物体检测</title>
    <link href="http://yoursite.com/2016/11/14/fast-r-cnn-%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B/"/>
    <id>http://yoursite.com/2016/11/14/fast-r-cnn-物体检测/</id>
    <published>2016-11-14T14:01:38.000Z</published>
    <updated>2016-11-22T12:46:15.919Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="卷积深度网络" scheme="http://yoursite.com/categories/%E5%8D%B7%E7%A7%AF%E6%B7%B1%E5%BA%A6%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="卷积" scheme="http://yoursite.com/tags/%E5%8D%B7%E7%A7%AF/"/>
    
  </entry>
  
  <entry>
    <title>ZigZag Conversion 回旋字符串</title>
    <link href="http://yoursite.com/2016/11/14/ZigZag-Conversion-%E5%9B%9E%E6%97%8B%E5%AD%97%E7%AC%A6%E4%B8%B2/"/>
    <id>http://yoursite.com/2016/11/14/ZigZag-Conversion-回旋字符串/</id>
    <published>2016-11-14T13:27:29.000Z</published>
    <updated>2016-11-18T11:52:17.947Z</updated>
    
    <content type="html"><![CDATA[<p>id：6. ZigZag Conversion   QuestionEditorial Solution  My Submissions<br>Total Accepted: 120341<br>Total Submissions: 469716<br>Difficulty: Easy<br>Contributors: Admin<br>The string “PAYPALISHIRING” is written in a zigzag pattern on a given number of rows like this: (you may want to display this pattern in a fixed font for better legibility)<br><img src="/images/zigzagconversion/1.png" alt=""><br> <a id="more"></a><br>And then read line by line: “PAHNAPLSIIGYIR”<br>Write the code that will take a string and make this conversion given a number of rows:</p>
<p>string convert(string text, int nRows);<br>convert(“PAYPALISHIRING”, 3) should return “PAHNAPLSIIGYIR”.<br>Subscribe to see which companies asked this question</p>
<p>这道题是一个变换，只要找到其中的规律就很好做题。<br><img src="/images/zigzagconversion/2.png" alt=""></p>
<p><code>假设结果存在一个string result中</code></p>
<p><code>原字符串存于s</code></p>
<p>经过观察我们可以发现<br>红色部分的变换为：</p>
<p><code>result.append(1,s[j*(numRows+numRows-2)+i])</code></p>
<p>绿色部分的变换为</p>
<p><code>result.append(1,s[(j+1)*(numRows+numRows-2)-i])</code></p>
<p>其中i是第i行，j是（红色或者绿）的第j个数</p>
<p>所以我们可以这么写代码：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="built_in">string</span> <span class="title">convert</span><span class="params">(<span class="built_in">string</span> s, <span class="keyword">int</span> numRows)</span> </span>&#123;</div><div class="line">        <span class="built_in">string</span> result;</div><div class="line">        <span class="keyword">if</span> (numRows==<span class="number">1</span>)</div><div class="line">        <span class="keyword">return</span> s;</div><div class="line">        <span class="keyword">if</span>(s.size()==<span class="number">0</span>)<span class="keyword">return</span> result;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;numRows;i++)</div><div class="line">        &#123;</div><div class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;(j*(numRows+numRows<span class="number">-2</span>)+i)&lt;s.size();j++)</div><div class="line">            &#123;result.append(<span class="number">1</span>,s[j*(numRows+numRows<span class="number">-2</span>)+i]);</div><div class="line">            <span class="keyword">if</span>(i==<span class="number">0</span>||i==numRows<span class="number">-1</span>)</div><div class="line">            <span class="keyword">continue</span>;</div><div class="line">            <span class="keyword">if</span>(((j+<span class="number">1</span>)*(numRows+numRows<span class="number">-2</span>)-i)&lt;s.size())</div><div class="line">            &#123;</div><div class="line">            result.append(<span class="number">1</span>,s[(j+<span class="number">1</span>)*(numRows+numRows<span class="number">-2</span>)-i]);</div><div class="line">            &#125;</div><div class="line"></div><div class="line">            &#125;</div><div class="line"></div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> result;</div><div class="line"></div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;id：6. ZigZag Conversion   QuestionEditorial Solution  My Submissions&lt;br&gt;Total Accepted: 120341&lt;br&gt;Total Submissions: 469716&lt;br&gt;Difficulty: Easy&lt;br&gt;Contributors: Admin&lt;br&gt;The string “PAYPALISHIRING” is written in a zigzag pattern on a given number of rows like this: (you may want to display this pattern in a fixed font for better legibility)&lt;br&gt;&lt;img src=&quot;/images/zigzagconversion/1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="leetcode" scheme="http://yoursite.com/categories/leetcode/"/>
    
    
      <category term="回旋字符串" scheme="http://yoursite.com/tags/%E5%9B%9E%E6%97%8B%E5%AD%97%E7%AC%A6%E4%B8%B2/"/>
    
      <category term="ZigZag Conversion" scheme="http://yoursite.com/tags/ZigZag-Conversion/"/>
    
  </entry>
  
  <entry>
    <title>PCA主成分分析</title>
    <link href="http://yoursite.com/2016/11/12/PCA%E9%99%8D%E7%BB%B4/"/>
    <id>http://yoursite.com/2016/11/12/PCA降维/</id>
    <published>2016-11-12T01:37:32.000Z</published>
    <updated>2016-11-18T14:35:15.671Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="主成分分析" scheme="http://yoursite.com/categories/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/"/>
    
    
      <category term="Principal Component Analysis" scheme="http://yoursite.com/tags/Principal-Component-Analysis/"/>
    
      <category term="主成分分析" scheme="http://yoursite.com/tags/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>最大回文串 Longest Palindromic Substring</title>
    <link href="http://yoursite.com/2016/11/11/%E6%9C%80%E5%A4%A7%E5%9B%9E%E6%96%87%E4%B8%B2-Longest-Palindromic-Substring/"/>
    <id>http://yoursite.com/2016/11/11/最大回文串-Longest-Palindromic-Substring/</id>
    <published>2016-11-11T12:20:16.000Z</published>
    <updated>2016-11-18T11:53:13.533Z</updated>
    
    <content type="html"><![CDATA[<p>id5. Longest Palindromic Substring   QuestionEditorial Solution  My Submissions<br>Total Accepted: 147621<br>Total Submissions: 614546<br>Difficulty: Medium<br>Contributors: Admin<br>Given a string s, find the longest palindromic substring in s. You may assume that the maximum length of s is 1000.<br> <a id="more"></a></p>
<p>Example:<br>Input: “babad”</p>
<p>Output: “bab”</p>
<p>Note: “aba” is also a valid answer.<br>Example:</p>
<p>Input: “cbbd”</p>
<p>Output: “bb”<br>最长回文串,首先最容易想到的是穷举所有的字串，然后判断是不是回文。<br>最开始的方法使用递归判断是不是回文：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//这是一种超时但是正确的做法。但是超时了。。</span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;string&gt;</span></span></div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</div><div class="line"><span class="function"><span class="keyword">bool</span> <span class="title">isPalindromic</span><span class="params">(<span class="built_in">string</span> s,<span class="keyword">int</span> i,<span class="keyword">int</span> j)</span></span></div><div class="line">&#123;</div><div class="line">    <span class="keyword">if</span> (i==j)</div><div class="line">    <span class="keyword">return</span> <span class="number">1</span>;</div><div class="line">    <span class="keyword">if</span>(s[i]!=s[j])</div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">    <span class="keyword">if</span> (i+<span class="number">1</span>==j)</div><div class="line">    <span class="keyword">return</span> <span class="number">1</span>;</div><div class="line">    <span class="keyword">return</span> isPalindromic(s,i+<span class="number">1</span>,j<span class="number">-1</span>);</div><div class="line">&#125;</div><div class="line">    <span class="function"><span class="built_in">string</span> <span class="title">longestPalindrome</span><span class="params">(<span class="built_in">string</span> s)</span> </span>&#123;</div><div class="line">        <span class="built_in">string</span> longestPalindromeString =s.substr(<span class="number">0</span>,<span class="number">1</span>);</div><div class="line">        <span class="built_in">string</span> str;</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i!=s.size();i++)</div><div class="line">        &#123;</div><div class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=i;j!=s.size();j++)</div><div class="line">            &#123;</div><div class="line">                str=s.substr(i,j-i+<span class="number">1</span>);</div><div class="line">             <span class="keyword">if</span>(isPalindromic(str,<span class="number">0</span>,str.size()<span class="number">-1</span>)&amp;&amp;(str.size()&gt;longestPalindromeString.size()))</div><div class="line">             longestPalindromeString=str;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> longestPalindromeString;</div><div class="line">    &#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></div><div class="line">&#123; <span class="built_in">string</span> s=<span class="string">"sdgdfhfgjhgghkjhljkldyhrtiiiiytrewqtyitutyiyopuip"</span>;</div><div class="line"><span class="built_in">cout</span>&lt;&lt;longestPalindrome(s);</div><div class="line">  <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>总结上面的做法，时间复杂度为  $o\left( n^2\log ^n \right) $<br>会发现做了很多重复的事情所以时间复杂度非常高，所以将思路变成穷举中心点，从中心按照奇数和偶数进行扩散，进而在扩散的过程就完成了回文的判断。节省了判断回文的时间。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">class</span> Solution &#123;</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    <span class="function"><span class="built_in">string</span> <span class="title">longestPalindrome</span><span class="params">(<span class="built_in">string</span> s)</span> </span>&#123;</div><div class="line">        <span class="built_in">string</span> longestPalindromeString =s.substr(<span class="number">0</span>,<span class="number">1</span>);</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i!=s.size();i++)</div><div class="line">        &#123;   <span class="comment">//奇数</span></div><div class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;((i-j)&gt;=<span class="number">0</span>)&amp;&amp;((i+j)&lt;=s.size()<span class="number">-1</span>);j++)</div><div class="line">            &#123;<span class="keyword">if</span>(s[i-j]!=s[i+j])</div><div class="line">             <span class="keyword">break</span>;</div><div class="line">             <span class="keyword">if</span> ((<span class="number">2</span>*j+<span class="number">1</span>)&gt;longestPalindromeString.size())</div><div class="line">             longestPalindromeString=s.substr(i-j,<span class="number">2</span>*j+<span class="number">1</span>);</div><div class="line">             &#125;</div><div class="line">             <span class="comment">//偶数</span></div><div class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;((i-j)&gt;=<span class="number">0</span>)&amp;&amp;((i+j+<span class="number">1</span>)&lt;=s.size()<span class="number">-1</span>);j++)</div><div class="line">            &#123; <span class="keyword">if</span>(s[i-j]!=s[i+j+<span class="number">1</span>])</div><div class="line">             <span class="keyword">break</span>;</div><div class="line">             <span class="keyword">if</span> ((<span class="number">2</span>*j+<span class="number">2</span>)&gt;longestPalindromeString.size())</div><div class="line">             longestPalindromeString=s.substr(i-j,<span class="number">2</span>*j+<span class="number">2</span>);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> longestPalindromeString;</div><div class="line">    &#125;</div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>这样的时间复杂度就为 $o\left( n^2 \right) $<br>顺别说一点，在写类的时候不要忘了在类后面加 <code>;</code>号，不然会提示</p>
<p><code>error: expected unqualified-id before string constant</code></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;id5. Longest Palindromic Substring   QuestionEditorial Solution  My Submissions&lt;br&gt;Total Accepted: 147621&lt;br&gt;Total Submissions: 614546&lt;br&gt;Difficulty: Medium&lt;br&gt;Contributors: Admin&lt;br&gt;Given a string s, find the longest palindromic substring in s. You may assume that the maximum length of s is 1000.&lt;br&gt;
    
    </summary>
    
      <category term="leetcode" scheme="http://yoursite.com/categories/leetcode/"/>
    
    
      <category term="最大回文串" scheme="http://yoursite.com/tags/%E6%9C%80%E5%A4%A7%E5%9B%9E%E6%96%87%E4%B8%B2/"/>
    
      <category term="Longest Palindromic Substring" scheme="http://yoursite.com/tags/Longest-Palindromic-Substring/"/>
    
  </entry>
  
  <entry>
    <title>激活函数</title>
    <link href="http://yoursite.com/2016/11/10/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    <id>http://yoursite.com/2016/11/10/激活函数/</id>
    <published>2016-11-10T12:27:17.000Z</published>
    <updated>2016-11-22T12:45:52.938Z</updated>
    
    <content type="html"><![CDATA[<p>在神经元的数学模型中，轴突所携带的信号(例如: $x_0$ )通过突触进行传递，由于突触的强弱不一，假设我们以 $w_0$ 表示，那么我们传到下一个神经元的树突处的信号就变成了 $w_0x_0$ 。其中突触强弱(参数w)是可学的，它控制了一个神经元对另一个神经元影响的大小和方向（正负）。然后树突接收到信号后传递到神经元内部<code>cell body</code>，与其他树突传递过来的信号一起进行加和，如果这个和的值大于某一个固定的阈值的话，神经元就会被激活，然后传递冲激信号给树突。在数学模型中我们假设传递冲激信号的时间长短并不重要，只有神经元被激活的频率用于传递信息. 我们将是否激活神经元的函数称为激活函数(activation function $f$ ), 它代表了轴突接收到冲激信号的频率。以前我们比较常用的一个激活信号是<code>sigmoid function</code> $σ$ ，因为它接收一个实值的信号（即上面所说的加和的值）然后将它压缩到 <code>0-1</code> 的范围内。我们在后面会介绍更多的激活函数。<br> <a id="more"></a></p>
<h1 id="传统Sigmoid系激活函数"><a href="#传统Sigmoid系激活函数" class="headerlink" title="传统Sigmoid系激活函数"></a>传统Sigmoid系激活函数</h1><p><img src="/images/activate/3.png" alt=""><br>传统神经网络中最常用的两个激活函数，<code>Sigmoid</code>系（Logistic-Sigmoid、Tanh-Sigmoid）被视为神经网络的核心所在。从数学上来看，非线性的Sigmoid函数对中央区的信号增益较大，对两侧区的信号增益小，在信号的特征空间映射上，有很好的效果。从神经科学上来看，中央区酷似神经元的兴奋态，两侧区酷似神经元的抑制态，因而在神经网络学习方面，可以将重点特征推向中央区，将非重点特征推向两侧区。</p>
<h2 id="sigmoid激活函数"><a href="#sigmoid激活函数" class="headerlink" title="sigmoid激活函数"></a>sigmoid激活函数</h2><p>sigmoid将一个实数输入映射到[0,1]范围内，如下图（左）所示。使用sigmoid作为激活函数存在以下几个问题：</p>
<ol>
<li>梯度饱和。当函数激活值接近于0或者1时，函数的梯度接近于0。在反向传播计算梯度过程中:<br>$$\delta^{\left(l\right)}=\left( W^{\left(l\right)} \right) ^T\delta ^{\left(l+1\right)}\cdot f’\left( z^{\left(L\right)}\right) $$<br>，每层残差接近于0，计算出的梯度也不可避免地接近于0。这样在参数微调过程中，会引起参数弥散问题，传到前几层的梯度已经非常靠近0了，参数几乎不会再更新。</li>
<li>函数输出不是以0为中心的。我们更偏向于当激活函数的输入是0时，输出也是0的函数.</li>
</ol>
<h2 id="tanh激活函数"><a href="#tanh激活函数" class="headerlink" title="tanh激活函数"></a>tanh激活函数</h2><p>tanh函数将一个实数输入映射到[-1,1]范围内，如上图（右）所示。当输入为0时，tanh函数输出为0，符合我们对激活函数的要求。然而，tanh函数也存在梯度饱和问题，导致训练效率低下。</p>
<h1 id="Softplus-amp-ReLu"><a href="#Softplus-amp-ReLu" class="headerlink" title="Softplus&amp;ReLu"></a>Softplus&amp;ReLu</h1><p><img src="/images/activate/4.png" alt=""></p>
<p>2001年，神经科学家Dayan、Abott从生物学角度，模拟出了脑神经元接受信号更精确的激活模型，该模型如左图所示：这个模型对比Sigmoid系主要变化有三点：<br><code>单侧抑制</code> <code>相对宽阔的兴奋边界</code> <code>稀疏激活性</code>（重点，可以看到红框里前端状态完全没有激活）<br>同年，Charles Dugas等人在做正数回归预测论文中偶然使用了Softplus函数，Softplus函数是Logistic-Sigmoid函数原函数。</p>
<h2 id="Softplus"><a href="#Softplus" class="headerlink" title="Softplus"></a>Softplus</h2><p>激活函数公式：<br>$$softplus\left( x \right) =\log \left( 1+e^x \right)<br>$$</p>
<p>按照论文的说法，一开始想要使用一个指数函数（天然正数）作为激活函数来回归，但是到后期梯度实在太大，难以训练，于是加了一个log来减缓上升趋势。<br>加了1是为了保证非负性。同年，Charles Dugas等人在NIPS会议论文中又调侃了一句，Softplus可以看作是强制非负校正函数 $max(0,x)$ 平滑版本。<br>偶然的是，同是2001年，ML领域的Softplus/Rectifier激活函数与神经科学领域的提出脑神经元激活频率函数有神似的地方，这促成了新的激活函数的研究。</p>
<h2 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h2><p>Relu激活函数（The Rectified Linear Unit）表达式为：<br>$$f(x)=max(0,x)$$</p>
<p><img src="/images/activate/5.png" alt=""></p>
<p>相比sigmoid和tanh函数，Relu激活函数的优点在于：</p>
<ol>
<li><code>梯度不饱和</code>。梯度计算公式为：1{x&gt;0}。因此在反向传播过程中，减轻了梯度弥散的问题，神经网络前几层的参数也可以很快的更新。</li>
<li><code>计算速度快</code>。正向传播过程中，sigmoid和tanh函数计算激活值时需要计算指数，而Relu函数仅需要设置阈值。如果x<0,f(x)=0，如果x>0,f(x)=x。加快了正向传播的计算速度。</0,f(x)=0，如果x></li>
</ol>
<p>因此，Relu激活函数可以极大地加快收敛速度，相比tanh函数，收敛速度可以加快6倍（如上图（右）所示）。</p>
<h1 id="激活函数的发展"><a href="#激活函数的发展" class="headerlink" title="激活函数的发展"></a>激活函数的发展</h1><h2 id="PReLU"><a href="#PReLU" class="headerlink" title="PReLU"></a>PReLU</h2><p>dsd<br>PReLU 是ReLU 和 LReLU的改进版本，具有非饱和性：</p>
<p><img src="/images/activate/11.png" alt=""><br><img src="/images/activate/6.png" alt=""><br>与LReLU相比，PReLU中的负半轴斜率a可学习而非固定。原文献建议初始化a为0.25，不采用正则。个人认为，是否采用正则应当视具体的数据库和网络，通常情况下使用正则能够带来性能提升。</p>
<p>虽然PReLU 引入了额外的参数，但基本不需要担心过拟合。例如，在上述cifar10+NIN实验中， PReLU比ReLU和ELU多引入了参数，但也展现了更优秀的性能。所以实验中若发现网络性能不好，建议从其他角度寻找原因。</p>
<p>与ReLU相比，PReLU收敛速度更快。因为PReLU的输出更接近0均值，使得SGD更接近natural gradient。证明过程参见原文[10]。</p>
<p>此外，作者在ResNet 中采用ReLU，而没有采用新的PReLU。这里给出个人浅见，不一定正确，仅供参考。首先，在上述LReLU实验中，负半轴斜率对性能的影响表现出一致性。对PReLU采用正则将激活值推向0也能够带来性能提升。这或许表明，小尺度或稀疏激活值对深度网络的影响更大。其次，ResNet中包含单位变换和残差两个分支。残差分支用于学习对单位变换的扰动。如果单位变换是最优解，那么残差分支的扰动应该越小越好。这种假设下，小尺度或稀疏激活值对深度网络的影响更大。此时，ReLU或许是比PReLU更好的选择.</p>
<h2 id="RReLU"><a href="#RReLU" class="headerlink" title="RReLU"></a>RReLU</h2><p>数学形式与PReLU类似，但RReLU[9]是一种非确定性激活函数，其参数是随机的。这种随机性类似于一种噪声，能够在一定程度上起到正则效果。作者在cifar10/100上观察到了性能提升。</p>
<h2 id="Maxout"><a href="#Maxout" class="headerlink" title="Maxout"></a>Maxout</h2><p>Maxout[13]是ReLU的推广，其发生饱和是一个零测集事件（measure zero event）。正式定义为：<br>$$\max \left( w_{1}^{T}x+b_1,…,w_{n}^{T}x+b_n \right) $$<br>Maxout网络能够近似任意连续函数，且当w2,b2,…,wn,bn为0时，退化为ReLU。 其实，Maxout的思想在视觉领域存在已久。例如，在HOG特征里有这么一个过程：计算三个通道的梯度强度，然后在每一个像素位置上，仅取三个通道中梯度强度最大的数值，最终形成一个通道。这其实就是Maxout的一种特例。</p>
<p>Maxout能够缓解梯度消失，同时又规避了ReLU神经元死亡的缺点，但增加了参数和计算量。</p>
<h2 id="ELU"><a href="#ELU" class="headerlink" title="ELU"></a>ELU</h2><p>ELU 融合了sigmoid和ReLU，具有左侧软饱性。其正式定义为：</p>
<p><img src="/images/activate/9.png" alt=""><br><img src="/images/activate/7.png" alt=""><br>右侧线性部分使得ELU能够缓解梯度消失，而左侧软饱能够让ELU对输入变化或噪声更鲁棒。ELU的输出均值接近于零，所以收敛速度更快。经本文作者实验，ELU的收敛性质的确优于ReLU和PReLU。在cifar10上，ELU 网络的loss 降低速度更快；在 ImageNet上，不加 Batch Normalization 30 层以上的 ReLU 网络会无法收敛，PReLU网络在MSRA的Fan-in （caffe ）初始化下会发散，而 ELU 网络在Fan-in/Fan-out下都能收敛 。</p>
<p>论文的另一个重要贡献是分析了Bias shift 现象与激活值的关系，证明了降低Bias shift 等价于把激活值的均值推向0。</p>
<h2 id="MPELU"><a href="#MPELU" class="headerlink" title="MPELU"></a>MPELU</h2><p>将分段线性与ELU统一到了一种形式下。在NIN+CIFAR10，本文作者发现ELU与LReLU性能一致，而与PReLU差距较大。经过分析，ELU泰勒展开的一次项就是LReLU。当在ELU前加入BN让输入集中在0均值附近， 则ELU与LReLU之差——泰勒展开高次项会变小，粗略估计，约55.57%的激活值误差小于0.01。因此，受PReLU启发，令α可学习能够提高性能。此外，引入参数β能够进一步控制ELU的函数形状。正式定义为<br><img src="/images/activate/10.png" alt=""><br><img src="/images/activate/8.png" alt=""><br>α 和 β可以使用正则。α, β 固定为1时，MPELU 退化为 ELU； β 固定为很小的值时，MPELU 近似为 PReLU；当α=0，MPELU 等价于 ReLU。</p>
<p>MPELU 的优势在于同时具备 ReLU、PReLU和 ELU的优点。首先，MPELU具备ELU的收敛性质，能够在无 Batch Normalization 的情况下让几十层网络收敛。其次，作为一般化形式， MPELU较三者的推广能力更强。简言之，MPELU = max(ReLU, PReLU, ELU)。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在神经元的数学模型中，轴突所携带的信号(例如: $x_0$ )通过突触进行传递，由于突触的强弱不一，假设我们以 $w_0$ 表示，那么我们传到下一个神经元的树突处的信号就变成了 $w_0x_0$ 。其中突触强弱(参数w)是可学的，它控制了一个神经元对另一个神经元影响的大小和方向（正负）。然后树突接收到信号后传递到神经元内部&lt;code&gt;cell body&lt;/code&gt;，与其他树突传递过来的信号一起进行加和，如果这个和的值大于某一个固定的阈值的话，神经元就会被激活，然后传递冲激信号给树突。在数学模型中我们假设传递冲激信号的时间长短并不重要，只有神经元被激活的频率用于传递信息. 我们将是否激活神经元的函数称为激活函数(activation function $f$ ), 它代表了轴突接收到冲激信号的频率。以前我们比较常用的一个激活信号是&lt;code&gt;sigmoid function&lt;/code&gt; $σ$ ，因为它接收一个实值的信号（即上面所说的加和的值）然后将它压缩到 &lt;code&gt;0-1&lt;/code&gt; 的范围内。我们在后面会介绍更多的激活函数。&lt;br&gt;
    
    </summary>
    
      <category term="卷积深度网络" scheme="http://yoursite.com/categories/%E5%8D%B7%E7%A7%AF%E6%B7%B1%E5%BA%A6%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="激活函数" scheme="http://yoursite.com/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>损失函数</title>
    <link href="http://yoursite.com/2016/11/10/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"/>
    <id>http://yoursite.com/2016/11/10/损失函数/</id>
    <published>2016-11-10T09:44:34.000Z</published>
    <updated>2016-11-22T12:47:34.420Z</updated>
    
    <content type="html"><![CDATA[<p>损失函数（loss function）是用来估量模型的预测值 $f(x)$ 与真实值Y的不一致程度，它是一个非负实值函数,通常使用 $L(Y, f(x))$ 来表示，损失函数越小，模型的鲁棒性就越好。损失函数是经验风险函数的核心部分，也是结构风险函数重要组成部分。模型的结构风险函数包括了经验风险项和正则项，通常可以表示成如下式子：<br><a id="more"></a><br>$$\theta^{*}=arg\underset{\theta}{\min}\frac{1}{N}\sum_{i=1}^N{L\left( y_i,f\left( x_i;\theta \right) \right) +\lambda \varPhi \left( \theta \right)}$$</p>
<p>其中，前面的均值函数表示的是经验风险函数，L代表的是损失函数，后面的 $\varPhi$ 是正则化项（regularizer）或者叫惩罚项（penalty term），它可以是L1，也可以是L2，或者其他的正则函数。整个式子表示的意思是找到使目标函数最小时的θ 值。下面主要列出几种常见的损失函数。</p>
<h1 id="log对数损失函数（逻辑回归）"><a href="#log对数损失函数（逻辑回归）" class="headerlink" title="log对数损失函数（逻辑回归）"></a>log对数损失函数（逻辑回归）</h1><p>有些人可能觉得逻辑回归的损失函数就是平方损失，其实并不是。平方损失函数可以通过线性回归在假设样本是高斯分布的条件下推导得到，而逻辑回归得到的并不是平方损失。在逻辑回归的推导中，它假设样本服从伯努利分布（0-1分布），然后求得满足该分布的似然函数，接着取对数求极值等等。而逻辑回归并没有求似然函数的极值，而是把极大化当做是一种思想，进而推导出它的经验风险函数为：最小化负的似然函数（即max F(y, f(x)) —-&gt; min -F(y, f(x)))。从损失函数的视角来看，它就成了log损失函数了。</p>
<p>log损失函数的标准形式：<br>$$ L\left( Y,P\left( Y|X \right) \right) =-\log P\left( Y|X \right)<br>$$<br>刚刚说到，取对数是为了方便计算极大似然估计，因为在MLE中，直接求导比较困难，所以通常都是先取对数再求导找极值点。损失函数 $L(Y, P(Y|X))$ 表达的是样本X在分类Y的情况下，使概率 $P(Y|X)$ 达到最大值（换言之，就是利用已知的样本分布，找到最有可能（即最大概率）导致这种分布的参数值；或者说什么样的参数才能使我们观测到目前这组数据的概率最大）。因为log函数是单调递增的，所以 $logP(Y|X)$ 也会达到最大值，因此在前面加上负号之后，最大化 $P(Y|X)$ 就等价于最小化 $L$ 了。<br>逻辑回归的 $P(Y=y|x)$ 表达式如下（为了将类别标签y统一为1和0，下面将表达式分开表示)：<br><img src="/images/lossfunction/1.png" alt=""><br>将它带入到上式，通过推导可以得到logistic的损失函数表达式，如下：<br><img src="/images/lossfunction/2.png" alt=""><br>逻辑回归最后得到的目标式子如下：<br>$$J\left( \theta \right) =-\frac{1}{m}\sum_{i=1}^m{\left[ y^i\log h_{\theta}\left( x^i \right) +\left( 1-y^i \right) \log \left( 1-h_{\theta}\left( x^i \right) \right) \right]}$$<br>上面是针对二分类而言的。</p>
<h1 id="平方损失函数（最小二乘法-Ordinary-Least-Squares-）"><a href="#平方损失函数（最小二乘法-Ordinary-Least-Squares-）" class="headerlink" title="平方损失函数（最小二乘法, Ordinary Least Squares ）"></a>平方损失函数（最小二乘法, Ordinary Least Squares ）</h1><p>最小二乘法是线性回归的一种，OLS将问题转化成了一个凸优化问题。在线性回归中，它假设样本和噪声都服从高斯分布（为什么假设成高斯分布呢？其实这里隐藏了一个小知识点，就是中心极限定理，可以参考<code>central limit theorem</code>），最后通过极大似然估计（MLE）可以推导出最小二乘式子。最小二乘的基本原则是：最优拟合直线应该是使各点到回归直线的距离和最小的直线，即平方和最小。换言之，OLS是基于距离的，而这个距离就是我们用的最多的欧几里得距离。为什么它会选择使用欧式距离作为误差度量呢（即Mean squared error， MSE），主要有以下几个原因：</p>
<ol>
<li>简单，计算方便；</li>
<li>欧氏距离是一种很好的相似性度量标准；</li>
<li>在不同的表示域变换后特征性质不变。<br>平方损失（Square loss）的标准形式如下：<br>$$L\left( Y,f\left( X \right) \right) =\left( Y-f\left( X \right) \right) ^2$$<br>当样本个数为n时，此时的损失函数变为：<br>$$L\left( Y,f\left( X \right) \right) =\sum_{i=1}^n{\left( Y-f\left( X \right) \right) ^2}$$<br>$Y-f(X)$ 表示的是残差，整个式子表示的是残差的平方和，而我们的目的就是最小化这个目标函数值（注：该式子未加入正则项），也就是最小化残差的平方和（residual sum of squares，RSS）。<br>而在实际应用中，通常会使用<code>均方差（MSE）</code>作为一项衡量指标，公式如下：<br>$$MSE=\frac{1}{n}\sum_{i=1}^n{\left( \widetilde{Y_i}-Y_i \right) ^2}$$<br><code>note：</code></li>
</ol>
<p>其求解过程转化为LSR(最小二乘回归)在求解时候。</p>
<ol>
<li>加入L1惩罚项，将变为 <code>lasso</code>问题，具体对lasso的求解将另起一文</li>
<li>加入L2惩罚项，将变为岭回归问题</li>
</ol>
<h1 id="指数损失函数（Adaboost）"><a href="#指数损失函数（Adaboost）" class="headerlink" title="指数损失函数（Adaboost）"></a>指数损失函数（Adaboost）</h1><p>学过Adaboost算法的人都知道，它是前向分步加法算法的特例，是一个加和模型，损失函数就是指数函数。在Adaboost中，经过m此迭代之后，可以得到<br>$$f_m\left( x \right) =f_{m-1}\left( x \right) +\alpha _mG_m\left( x \right) $$<br>Adaboost每次迭代时的目的是为了找到最小化下列式子时的参数α 和G：<br>$$arg\underset{\alpha ,G}{\min}=\sum_{i=1}^N{\exp \left[ -y_i\left( f_{m-1}\left( x_i \right) +\alpha G\left( x_i \right) \right) \right]}$$<br>而指数损失函数(exp-loss）的标准形式如下<br>  $$L\left( Y,f\left( X \right) \right) =\exp \left[ -yf\left( x \right) \right] $$<br>  可以看出，Adaboost的目标式子就是指数损失，在给定n个样本的情况下，Adaboost的损失函数为：<br>  $$L\left( Y,f\left( X \right) \right) =\frac{1}{n}\sum_{i=1}^n{\exp \left[ -yf\left( x \right) \right]}$$</p>
<h1 id="Hinge损失函数（SVM）"><a href="#Hinge损失函数（SVM）" class="headerlink" title="Hinge损失函数（SVM）"></a>Hinge损失函数（SVM）</h1><p>在机器学习算法中，hinge损失函数和SVM是息息相关的。在线性支持向量机中，最优化问题可以等价于下列式子：<br>$$\underset{w,b}{\min}\sum_i^N{\left[ 1-y_i\left( w\cdot x_i+b \right) \right] _++\lambda ||w||^2}$$<br>下面来对式子做个变形，令：<br>$$\left[ 1-y_i\left( w\cdot x_i+b \right) \right] _+=\xi _i$$<br>于是，原式就变成了：<br>$$\underset{w,b}{\min}\sum_i^N{\xi _i+\lambda ||w||^2}$$<br>另 $\lambda =\frac{1}{2C}$</p>
<p>$$\underset{w,b}{\min}\frac{1}{C}\left( C\sum_i^N{\xi _i+\frac{1}{2}||w||^2} \right)$$<br>可以看出，该式子与下式非常相似：</p>
<h2 id="Hinge-损失函数的标准形式"><a href="#Hinge-损失函数的标准形式" class="headerlink" title="Hinge 损失函数的标准形式:"></a>Hinge 损失函数的标准形式:</h2><p>$$L\left( y \right) =\max \left( 0,1-y\tilde{y} \right) ,y=\pm 1$$<br>可以看出，当 $|y|&gt;=1$ 时，$L(y)=0$ 。</p>
<h1 id="其它损失函数"><a href="#其它损失函数" class="headerlink" title="其它损失函数"></a>其它损失函数</h1><h2 id="0-1损失函数"><a href="#0-1损失函数" class="headerlink" title="0-1损失函数"></a>0-1损失函数</h2><p><img src="/images/lossfunction/3.png" alt=""></p>
<h2 id="绝对值损失函数"><a href="#绝对值损失函数" class="headerlink" title="绝对值损失函数"></a>绝对值损失函数</h2><p><img src="/images/lossfunction/4.png" alt=""></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p><img src="/images/lossfunction/5.png" alt=""><br>参数越多，模型越复杂，而越复杂的模型越容易过拟合。过拟合就是说模型在训练数据上的效果远远好于在测试集上的性能。此时可以考虑正则化，通过设置正则项前面的hyper parameter，来权衡损失函数和正则项，减小参数规模，达到模型简化的目的，从而使模型具有更好的泛化能力。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;损失函数（loss function）是用来估量模型的预测值 $f(x)$ 与真实值Y的不一致程度，它是一个非负实值函数,通常使用 $L(Y, f(x))$ 来表示，损失函数越小，模型的鲁棒性就越好。损失函数是经验风险函数的核心部分，也是结构风险函数重要组成部分。模型的结构风险函数包括了经验风险项和正则项，通常可以表示成如下式子：&lt;br&gt;
    
    </summary>
    
      <category term="卷积深度网络" scheme="http://yoursite.com/categories/%E5%8D%B7%E7%A7%AF%E6%B7%B1%E5%BA%A6%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="损失函数" scheme="http://yoursite.com/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>聚类分析</title>
    <link href="http://yoursite.com/2016/11/09/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/"/>
    <id>http://yoursite.com/2016/11/09/聚类分析/</id>
    <published>2016-11-09T09:33:59.000Z</published>
    <updated>2016-11-10T12:24:59.563Z</updated>
    
    <content type="html"><![CDATA[<p>聚类分析将数据划分成有意义或有用的组（簇）。聚类分析仅根据在数据中发现的描述对象及其关系的信息，将数据对象分组。其目标是，组内的对象相互之间是相似的，而不同组中的对象是不同的。<br> <a id="more"></a></p>
<h1 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h1><p>一个好的聚类方法要能产生高质量的聚类结果——簇，这些簇要具备以下两个特点：</p>
<ol>
<li>高的簇内相似性</li>
<li>低的簇间相似性</li>
</ol>
<p>聚类结果的好坏取决于该聚类方法采用的相似性评估方法以及该方法的具体实现<br>聚类方法的好坏还取决于该方法是否能发现某些还是所有的隐含模式</p>
<p><img src="/images/clutster/1.png" alt=""></p>
<p>聚类可以分为：</p>
<ol>
<li>划分聚类（Partitional Clustering）</li>
<li>层次聚类（Hierarchical Clustering）</li>
<li>互斥（重叠）聚类（exclusive clustering）</li>
<li>非互斥聚类（non-exclusive）</li>
<li>模糊聚类（fuzzy clustering）</li>
<li>完全聚类（complete clustering）</li>
<li>部分聚类（partial clustering）</li>
</ol>
<h2 id="划分聚类"><a href="#划分聚类" class="headerlink" title="划分聚类"></a>划分聚类</h2><p>划分聚类简单地将数据对象集划分成不重叠的子集，使得每个数据对象恰在一个子集。</p>
<p><img src="/images/clutster/2.png" alt=""></p>
<h2 id="层次聚类"><a href="#层次聚类" class="headerlink" title="层次聚类"></a>层次聚类</h2><p>层次聚类是嵌套簇的集族，组织成一棵树。<br><img src="/images/clutster/3.png" alt=""></p>
<h2 id="互斥聚类（exclusive）"><a href="#互斥聚类（exclusive）" class="headerlink" title="互斥聚类（exclusive）"></a>互斥聚类（exclusive）</h2><p>每个对象都指派到单个簇.</p>
<h2 id="重叠聚类（overlapping）或非互斥聚类（non-exclusive）"><a href="#重叠聚类（overlapping）或非互斥聚类（non-exclusive）" class="headerlink" title="重叠聚类（overlapping）或非互斥聚类（non-exclusive）"></a>重叠聚类（overlapping）或非互斥聚类（non-exclusive）</h2><p>聚类用来反映一个对象.同时属于多个组（类）这一事实。<br>例如：在大学里，一个人可能既是学生，又是雇员</p>
<h2 id="模糊聚类（Fuzzy-clustering-）"><a href="#模糊聚类（Fuzzy-clustering-）" class="headerlink" title="模糊聚类（Fuzzy clustering ）"></a>模糊聚类（Fuzzy clustering ）</h2><p>每个对象以一个0（绝对不属于）和1（绝对属于）之间的隶属权值属于每个簇。<br>换言之，簇被视为模糊集。</p>
<h2 id="部分聚类（Partial）"><a href="#部分聚类（Partial）" class="headerlink" title="部分聚类（Partial）"></a>部分聚类（Partial）</h2><p>部分聚类中数据集某些对象可能不属于明确定义的组。如：一些对象可能是离群点、噪声。</p>
<h2 id="完全聚类（complete）"><a href="#完全聚类（complete）" class="headerlink" title="完全聚类（complete）"></a>完全聚类（complete）</h2><p>完全聚类将每个对象指派到一个簇。</p>
<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><h2 id="簇的分类"><a href="#簇的分类" class="headerlink" title="簇的分类"></a>簇的分类</h2><p>簇是同一性状物体的集合<br>按照性状的分类不同可以将簇分为</p>
<ol>
<li>明显分离的</li>
</ol>
<p>每个点到同簇中任一点的距离比到不同簇中所有点的距离更近。</p>
<ol>
<li>基于原型的</li>
</ol>
<p>每个对象到定义该簇的原型的距离比到其他簇的原型的距离更近。<br>对于具有连续属性的数据，簇的原型通常是质心，即簇中所有点的平均值。<br>当质心没有意义时，原型通常是中心点，即簇中最有代表性的点。</p>
<p>基于中心的（ Center-Based）的簇：<br>每个点到其簇中心的距离比到任何其他簇中心的距离更近。</p>
<ol>
<li>基于图的</li>
</ol>
<p>如果数据用图表示，其中节点是对象，而边代表对象之间的联系。</p>
<p>簇可以定义为连通分支（connected component）：互相连通但不与组外对象连通的对象组。</p>
<p>基于近邻的（ Contiguity-Based）：其中两个对象是相连的，仅当它们的距离在指定的范围内。这意味着，每个对象到该簇某个对象的距离比到不同簇中任意点的距离更近。</p>
<ol>
<li>基于密度的</li>
</ol>
<p>簇是对象的稠密区域，被低密度的区域环绕。</p>
<ol>
<li><p>概念簇<br>可以把簇定义为有某种共同性质的对象的集合。<br>例如：基于中心的聚类。还有一些簇的共同性质需要更复杂的算法才能识别出来。</p>
<p>本系列文章将探究各个聚类方式之间的区别</p>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;聚类分析将数据划分成有意义或有用的组（簇）。聚类分析仅根据在数据中发现的描述对象及其关系的信息，将数据对象分组。其目标是，组内的对象相互之间是相似的，而不同组中的对象是不同的。&lt;br&gt;
    
    </summary>
    
      <category term="聚类分析" scheme="http://yoursite.com/categories/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="聚类分析" scheme="http://yoursite.com/tags/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>互斥聚类-k-means聚类</title>
    <link href="http://yoursite.com/2016/11/09/k-means%E8%81%9A%E7%B1%BB/"/>
    <id>http://yoursite.com/2016/11/09/k-means聚类/</id>
    <published>2016-11-09T08:56:52.000Z</published>
    <updated>2016-11-10T12:11:58.912Z</updated>
    
    <content type="html"><![CDATA[<p> 在数据挖掘中，K-Means算法是一种cluster analysis的算法， 其主要是来计算数据聚集算法，主要通过不断地取离种子点最近均值的算法。<br> <a id="more"></a></p>
<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>K-Means算法主要解决的问题如下图所示。我们可以看到，在图的左边有一些点，我们用肉眼可以看出来有四个点群，但是我们怎么通过计算机程序找出这几个点群来呢？</p>
<p>于是就出现了我们的K-Means算法。<br><img src="/images/kmeans/1.png" alt=""><br>算法概要如下图所示：<br><img src="/images/kmeans/2.png" alt=""><br>从上图中，我们可以看到，A，B，C，D，E是五个在图中点。而灰色的点是我们的种子点，也就是我们用来找点群的点。有两个种子点，所以K=2。</p>
<p>然后，K-Means的算法如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">1. 随机在图中取K（这里K=2）个种子点</div><div class="line"></div><div class="line">2. 然后对图中的所有点求到这K个种子点的距离，假如点Pi离种子点Si最近，</div><div class="line">那么Pi属于Si点群。</div><div class="line">（上图中，我们可以看到A，B属于上面的种子点，C，D，E属于下面中部的种子点）</div><div class="line">3. 我们要移动种子点到属于他的“点群”的中心。（见图上的第三步）</div><div class="line">然后重复第2）和第3）步直到，种子点没有移动（我们可以看到图中的第四步上面的种子点聚合了A，B，C，下面的种子点聚合了D，E）。</div></pre></td></tr></table></figure>
<p>使用公式可以表示为：<br>$$\varUpsilon =\sum_{k=1}^K{\sum_{i=1}^L{dist\left( x_i-u_k \right)}}$$<br>而$dist$距离函数可以分为：</p>
<ol>
<li>Minkowski Distance（闵可夫斯基距离）<br>$$<br>d_{i,j}=\sqrt[\lambda]{\sum_{k=1}^n{|x_{i,k}-x_{j,k}|}^{\lambda}}<br>$$<br>$\lambda$ 可以随意取值，可以是负数，也可以是正数，或是无穷大</li>
<li>Euclidean Distance(欧拉距离)</li>
</ol>
<p>$$<br>d_{i,j}=\sqrt[]{\sum_{k=1}^n{|x_{i,k}-x_{j,k}|}^2}<br>$$<br>其形式为 Minkowski Distance 为 $\lambda$=2时候的特殊形式。</p>
<ol>
<li>CityBlock Distance （CB距离）<br>$$<br>d_{i,j}=\sum_{k=1}^n{|x_{i,k}-x_{j,k}|}<br>$$<br>也就是第一个公式 $\lambda$=1的情况。</li>
</ol>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><h2 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a>实验目的</h2><p>在模拟k-means的实验中我们使用深度学习网络vgg16在一个层的feature maps 来进行模拟实验，用来验证聚类效果，输入图片为一个行人。我们使用vgg16 conv1-2产生的feature maps进行实验。假设我们产生的feature maps 为 $\psi \in R^{m\times n\times k}$ ,其中 $m\times n$ 为feature大小, k为map的个数。首先每个feature进行向量化，从而将其转化为 $\psi \in R^{m* n\times k}$ 。使用k-means对一个层的feature maps进行聚类，并可视化效果。本实验中使用欧式距离。</p>
<h2 id="工具"><a href="#工具" class="headerlink" title="工具"></a>工具</h2><ol>
<li>实验使用vlfeat工具包<br>下载地址： <a href="https://github.com/unsky/vlfeat" target="_blank" rel="external">https://github.com/unsky/vlfeat</a></li>
<li>在vlfeat\toolbox中使用vl_setup启动工具包</li>
</ol>
<h2 id="实验过程"><a href="#实验过程" class="headerlink" title="实验过程"></a>实验过程</h2><p>假设feature maps已经存在于 res1.mat 中<br>运行代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">load(&apos;res1.mat&apos;);</div><div class="line">a=res(23).x;</div><div class="line">[w,e,r]=size(a);</div><div class="line">a=reshape(a,w*e,r);</div><div class="line"> [C, A] = vl_kmeans(a, 10) ;</div><div class="line"> for i=1:10,</div><div class="line"> fea=C(:,i);</div><div class="line"> fea=reshape(fea,w,e);</div><div class="line">  n = mapminmax(fea, 0, 1);</div><div class="line"> subplot(2,5,i);</div><div class="line"> imshow(n);</div><div class="line"> hold on;</div><div class="line"> end</div></pre></td></tr></table></figure></p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><ol>
<li>原始64个feature的可视化：<br><img src="/images/kmeans/3.png" alt=""></li>
<li>k-means （k=10）<br><img src="/images/kmeans/4.png" alt=""></li>
</ol>
<p>k=5<br><img src="/images/kmeans/5.png" alt=""></p>
<p>k=1<br><img src="/images/kmeans/6.png" alt=""></p>
<h1 id="k-means-优缺点"><a href="#k-means-优缺点" class="headerlink" title="k-means 优缺点"></a>k-means 优缺点</h1><p> 优点：</p>
<ol>
<li>算法简单</li>
<li>适用于球形簇</li>
<li>二分k均值等变种算法运行良好，不受初始化问题的影响。</li>
</ol>
<p>缺点：</p>
<ol>
<li>不能处理非球形簇、不同尺寸和不同密度的簇</li>
<li>对离群点、噪声敏感</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt; 在数据挖掘中，K-Means算法是一种cluster analysis的算法， 其主要是来计算数据聚集算法，主要通过不断地取离种子点最近均值的算法。&lt;br&gt;
    
    </summary>
    
      <category term="聚类分析" scheme="http://yoursite.com/categories/%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="k-means" scheme="http://yoursite.com/tags/k-means/"/>
    
      <category term="聚类" scheme="http://yoursite.com/tags/%E8%81%9A%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>手把手将atom打造成c++/c编程利器</title>
    <link href="http://yoursite.com/2016/11/08/%E6%89%8B%E6%8A%8A%E6%89%8B%E5%B0%86atom%E6%89%93%E9%80%A0%E6%88%90c-c%E7%BC%96%E7%A8%8B%E5%88%A9%E5%99%A8/"/>
    <id>http://yoursite.com/2016/11/08/手把手将atom打造成c-c编程利器/</id>
    <published>2016-11-08T02:31:28.000Z</published>
    <updated>2016-11-10T12:11:56.449Z</updated>
    
    <content type="html"><![CDATA[<p>Atom是由GitHub开发的自由及开放源代码的文字与代码编辑器，支持OS X、Windows和Linux操作系统，支持Node.js所写的插件，并内置Git版本控制系统。多数的延伸包皆为开放源代码授权，并由社区建置与维护。Atm基于Chromium并使用CoffeeScript撰写。Atom也可当作IDE使用。<br> <a id="more"></a></p>
<h1 id="安装atom"><a href="#安装atom" class="headerlink" title="安装atom"></a>安装atom</h1><p> 原则自己的平台安装，本文所有操作均在 win10中进行。</p>
<p> 官方下载地址：<a href="https://atom.io/" target="_blank" rel="external">https://atom.io/</a></p>
<p> 安装之后进入欢迎界面<br> <img src="/images/atomle/1.png" alt=""><br>原始的atom已经安装了一些插件。但是我们需要将其打造成一个c/c++ IDE.</p>
<h1 id="编译和调试插件-gpp-compliler"><a href="#编译和调试插件-gpp-compliler" class="headerlink" title="编译和调试插件 gpp-compliler"></a>编译和调试插件 gpp-compliler</h1><p>编译和调试是ide的基本功能不可或缺。</p>
<p>gpp-compliler 安装依赖于 MinGW 下载地址：<a href="http://www.mingw.org/" target="_blank" rel="external">http://www.mingw.org/</a></p>
<p>MinGW(Minimalist GNU For Windows)是个精简的Windows平台C/C++、ADA及Fortran编译器，相比Cygwin而言，体积要小很多，使用较为方便。</p>
<h2 id="运行刚刚下载的安装程序"><a href="#运行刚刚下载的安装程序" class="headerlink" title="运行刚刚下载的安装程序"></a>运行刚刚下载的安装程序</h2><p> <img src="/images/atomle/2.png" alt=""><br> 安装到D:\MinGW，点”Continue”。之后在桌面会形成一个安装器：<br>  <img src="/images/atomle/3.png" alt=""><br>  运行</p>
<h2 id="选择安装组件"><a href="#选择安装组件" class="headerlink" title="选择安装组件"></a>选择安装组件</h2><p>  运行安装程序。<img src="/images/atomle/4.png" alt="">  选择需要安装的组件，右键选择Mark for Installation,之后选择Installation -&gt; Apply Changes。</p>
<h2 id="GCC"><a href="#GCC" class="headerlink" title="GCC"></a>GCC</h2><p>  这里重点要提到的是GCC组件的安装，如图所示<br>      <img src="/images/atomle/5.png" alt=""><br>      先选择左边的”MinGW Base System”选项，之后再右边找到mingw-gcc。最好选择bin,dev和lic三个组件进行安装。</p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p> 设置MinGW环境变量<br>鼠标右键“我的电脑”-&gt;“属性”，选择“高级”选项卡下的“环境变量”，在系统变量里点“新建”，之后填写MinGW的安装路径，如下：<br>      <img src="/images/atomle/6.png" alt=""><br>      之后找到Path，在最前面添加下面这段声明，之后点击确定。安装完成后，在MinGW\bin的目录下，会有一个名为gcc.exe的可执行文件。在 <code>cmd</code> 运行  <code>gcc -v</code>会出现版本信息，如果显示，则安装成功。回到atom,新建一个cpp文件，代码中我们加个错误</p>
<pre><code><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">#include &lt;iostream&gt;</div><div class="line">#include &lt;vector&gt;</div><div class="line">using namespace std;</div><div class="line">int main()&#123;</div><div class="line">    int aaa;</div><div class="line">    cin&gt;&gt;aaa;</div><div class="line">aa</div><div class="line">  cout&lt;&lt;aaa&lt;&lt;endl;</div><div class="line"></div><div class="line">        return 0;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><p>  运行 <code>F5</code><br>    <img src="/images/atomle/7.png" alt=""><br>    错误提示在右上角。<br>    将代码修改正确<br>        <img src="/images/atomle/8.png" alt=""><br>        显示控制台结果.</p>
<h1 id="代码错误检测-linter-gcc"><a href="#代码错误检测-linter-gcc" class="headerlink" title="代码错误检测 linter-gcc"></a>代码错误检测 linter-gcc</h1><p>linter-gcc 安装依赖于linter 首先安装linter包。同时还依赖于 gcc 在上一步我们已经安装了gcc并且已经加入了路径，如果没有请自行安装。</p>
<p>只需在 linter-gcc的设置里面<br> <img src="/images/atomle/9.png" alt=""><br><code>F5</code> 运行一段代码错误代码，可以显示：<br><img src="/images/atomle/10.png" alt=""><br>  到这里 atom已经可以完成我们编译所需的环境，剩下的可以进一步就行优化推荐一些优秀的插件</p>
<h1 id="高亮选择-highlight-selected"><a href="#高亮选择-highlight-selected" class="headerlink" title="高亮选择 highlight-selected"></a>高亮选择 highlight-selected</h1><p>可以高亮选择的关键字<br>    <img src="/images/atomle/11.png" alt=""></p>
<h1 id="自动美化代码-atom-beautiful"><a href="#自动美化代码-atom-beautiful" class="headerlink" title="自动美化代码 atom-beautiful"></a>自动美化代码 atom-beautiful</h1><h1 id="minimap"><a href="#minimap" class="headerlink" title="minimap"></a>minimap</h1><p>和submit一种风格的快速浏览窗口。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Atom是由GitHub开发的自由及开放源代码的文字与代码编辑器，支持OS X、Windows和Linux操作系统，支持Node.js所写的插件，并内置Git版本控制系统。多数的延伸包皆为开放源代码授权，并由社区建置与维护。Atm基于Chromium并使用CoffeeScript撰写。Atom也可当作IDE使用。&lt;br&gt;
    
    </summary>
    
      <category term="环境搭建" scheme="http://yoursite.com/categories/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="atom" scheme="http://yoursite.com/tags/atom/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络</title>
    <link href="http://yoursite.com/2016/11/02/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%E5%8E%86%E7%A8%8B/"/>
    <id>http://yoursite.com/2016/11/02/卷积神经网络学习历程/</id>
    <published>2016-11-01T16:10:30.000Z</published>
    <updated>2016-11-22T12:46:50.778Z</updated>
    
    <content type="html"><![CDATA[<p>  神经网络算法领域最初是被对生物神经系统建模这一目标启发，但随后与其分道扬镳，成为一个工程问题，并在机器学习领域取得良好效果。然而，讨论将还是从对生物系统的一个高层次的简略描述开始，因为神经网络毕竟是从这里得到了启发.<br><a id="more"></a></p>
<h1 id="神经元建模"><a href="#神经元建模" class="headerlink" title="神经元建模"></a>神经元建模</h1><p>  大脑的基本计算单位是神经元（neuron）。人类的神经系统中大约有860亿个神经元，它们被大约10^14-10^15个突触（synapses）连接起来。下面图表的左边展示了一个生物学的神经元，右边展示了一个常用的数学模型。每个神经元都从它的树突获得输入信号，然后沿着它唯一的轴突（axon）产生输出信号。轴突在末端会逐渐分枝，通过突触和其他神经元的树突相连。</p>
<p>  在神经元的计算模型中，沿着轴突传播的信号（比如 $x_0$ ）将基于突触的突触强（比如 $w_0$ ），与其他神经元的树突进行乘法交互（比如$w_0x_0$）。其观点是，突触的强度（也就是权重），是可学习的且可以控制一个神经元对于另一个神经元的影响强度（还可以控制影响方向：使其兴奋（正权重）或使其抑制（负权重））。在基本模型中，树突将信号传递到细胞体，信号在细胞体中相加。如果最终之和高于某个阈值，那么神经元将会激活，向其轴突输出一个峰值信号。在计算模型中，我们假设峰值信号的准确时间点不重要，是激活信号的频率在交流信息。基于这个速率编码的观点，将神经元的激活率建模为激活函数（activation function）f，它表达了轴突上激活信号的频率。由于历史原因，激活函数常常选择使用sigmoid函数 $\sigma$，该函数输入实数值（求和后的信号强度），然后将输入值压缩到0-1之间。在本节后面部分会看到这些激活函数的各种细节。</p>
<p>  <img src="/images/cnn/1.png" alt=""><br>  左边是生物神经元，右边是数学模型。</p>
<h1 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h1><h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><p>自然图像有其固有特性，也就是说，图像的一部分的统计特性与其他部分是一样的。这也意味着我们在这一部分学习的特征也能用在另一部分上，所以对于这个图像上的所有位置，我们都能使用同样的学习特征。</p>
<p>更恰当的解释是，当从一个大尺寸图像中随机选取一小块，比如说 8x8 作为样本，并且从这个小块样本中学习到了一些特征，这时我们可以把从这个 8x8 样本中学习到的特征作为探测器，应用到这个图像的任意地方中去。特别是，我们可以用从 8x8 样本中所学习到的特征跟原本的大尺寸图像作卷积，从而对这个大尺寸图像上的任一位置获得一个不同特征的激活值。</p>
<p>下面给出一个具体的例子：假设你已经从一个 96x96 的图像中学习到了它的一个 8x8 的样本所具有的特征，假设这是由有 100 个隐含单元的自编码完成的。为了得到卷积特征，需要对 96x96 的图像的每个 8x8 的小块图像区域都进行卷积运算。也就是说，抽取8x8 的小块区域，并且从起始坐标开始依次标记为（1，1），（1，2），…，一直到（89，89），然后对抽取的区域逐个运行训练过的稀疏自编码来得到特征的激活值。在这个例子里，显然可以得到 100 个集合，每个集合含有 89x89 个卷积特征。<br>  <img src="/images/cnn/2.gif" alt=""></p>
<p>  假设给定了 $r \times c$ 的大尺寸图像，将其定义为 xlarge。首先通过从大尺寸图像中抽取的 $a \times b$ 的小尺寸图像样本 $x_{small}$ 训练稀疏自编码，计算 $f = σ(W(1)x_{small} + b(1))$ （σ 是一个 sigmoid 型函数）得到了 k 个特征， 其中 W(1) 和 b(1) 是可视层单元和隐含单元之间的权重和偏差值。对于每一个 $a \times b$ 大小的小图像 $x_s$，计算出对应的值  $f_s = σ(W(1)x_s + b(1))$ ，对这些 fconvolved 值做卷积，就可以得到  $k \times (r - a + 1) \times (c - b + 1)$  个卷积后的特征的矩阵。</p>
<h3 id="窄卷积-vs-宽卷积"><a href="#窄卷积-vs-宽卷积" class="headerlink" title="窄卷积 vs 宽卷积"></a>窄卷积 vs 宽卷积</h3><p>在上文中解释卷积运算的时候，忽略了如何使用滤波器的一个小细节。在矩阵的中部使用3x3的滤波器没有问题，在矩阵的边缘该怎么办呢？左上角的元素没有顶部和左侧相邻的元素，该如何滤波呢？解决的办法是采用补零法（zero-padding）。所有落在矩阵范围之外的元素值都默认为0。这样就可以对输入矩阵的每一个元素做滤波了，输出一个同样大小或是更大的矩阵。补零法又被称为是宽卷积，不使用补零的方法则被称为窄卷积。在具体的试验中就是<code>pad</code>字段设置 <code>0 or other</code></p>
<p>1D的例子如图所示：<br>  <img src="/images/cnn/3.png" alt="">窄卷积 vs 宽卷积。滤波器长度为5，输入长度为7。</p>
<h3 id="步长"><a href="#步长" class="headerlink" title="步长"></a>步长</h3><p>卷积运算的另一个超参数是步长，即每一次滤波器平移的距离。上面所有例子中的步长都是1，相邻两个滤波器有重叠。步长越大，则用到的滤波器越少，输出的值也越少.<br>在实验中使用<code>strike</code>进行控制<br>  <img src="/images/cnn/4.png" alt=""></p>
<h2 id="池化-pooling"><a href="#池化-pooling" class="headerlink" title="池化 pooling"></a>池化 pooling</h2><p>卷积神经网络的一个重要概念就是池化层，一般是在卷积层之后。池化层对输入做降采样。常用的池化做法是对每个滤波器的输出求最大值。我们并不需要对整个矩阵都做池化，可以只对某个窗口区间做池化。例如，下图所示的是2x2窗口的最大值池化（在NLP里，我们通常对整个输出做池化，每个滤波器只有一个输出值）：<br>  <img src="/images/cnn/5.png" alt=""></p>
<p>池化的特点之一就是它输出一个固定大小的矩阵，这对分类问题很有必要。例如，如果你用了1000个滤波器，并对每个输出使用最大池化，那么无论滤波器的尺寸是多大，也无论输入数据的维度如何变化，你都将得到一个1000维的输出。这让你可以应用不同长度的句子和不同大小的滤波器，但总是得到一个相同维度的输出结果，传入下一层的分类器。</p>
<p>池化还能降低输出结果的维度，（理想情况下）却能保留显著的特征。你可以认为每个滤波器都是检测一种特定的特征，例如，检测句子是否包含诸如“not amazing”等否定意思。如果这个短语在句子中的某个位置出现，那么对应位置的滤波器的输出值将会非常大，而在其它位置的输出值非常小。通过采用取最大值的方式，能将某个特征是否出现在句子中的信息保留下来，但是无法确定它究竟在句子的哪个位置出现。这个信息出现的位置真的很重要吗？确实是的，它有点类似于一组n-grams模型的行为。尽管丢失了关于位置的全局信息（在句子中的大致位置），但是滤波器捕捉到的局部信息却被保留下来了，比如“not amazing”和“amazing not”的意思就大相径庭。</p>
<p>在图像识别领域，池化还能提供平移和旋转不变性。若对某个区域做了池化，即使图像平移/旋转几个像素，得到的输出值也基本一样，因为每次最大值运算得到的结果总是一样的</p>
<h2 id="前向"><a href="#前向" class="headerlink" title="前向"></a>前向</h2><p>现在设节点 $i$ 和节点 $j$ 之间的权值为 $w_{i,j}$ ，节点 $j$ 的阀值为 $b_j$ ，每个节点的输出值为 $x_j$ ，而每个节点的输出值是根据上层所有节点的输出值、当前节点与上一层所有节点的权值和当前节点的阀值还有激活函数来实现的。具体计算方法如下</p>
<p>$$S_j=\sum_{i=0}^{m-1}{w_{i,j}x_i+b_j}$$<br>$$x_j=f\left( S_j \right) $$</p>
<p>其中 $f$ 为激活函数，一般选取S型函数或者线性函数。正向传递的过程比较简单，按照上述公式计算即可。在BP神经网络中，输入层节点没有阀值。</p>
<h3 id="卷积的前向"><a href="#卷积的前向" class="headerlink" title="卷积的前向"></a>卷积的前向</h3><p>如下图，卷积层的输入来源于输入层或者pooling层。每一层的多个卷积核大小相同，在这个网络中，使用的卷积核均为 $5\times 5$ 。<br>  <img src="/images/cnn/6.png" alt=""></p>
<p>如图输入为 $28 \times 28$ 的图像，经过 $5 \times5$ 的卷积之后，得到一个 $(28-5+1)\times (28-5+1) = 24\times 24$ 的map。卷积层2的每个map是不同卷积核在前一层每个map上进行卷积，并将每个对应位置上的值相加然后再加上一个偏置项。</p>
<p>  <img src="/images/cnn/7.png" alt=""><br>每次用卷积核与map中对应元素相乘，然后移动卷积核进行下一个神经元的计算。如图中矩阵C的第一行第一列的元素2，就是卷积核在输入map左上角时的计算结果。在图中也很容易看到，输入为一个 $4\times 4$ 的map，经过 $2\times 2$ 的卷积核卷积之后，结果为一个 $(4-2+1) \times (4-2+1) = 3\times 3$ 的map。</p>
<h3 id="卷积前向的caffe实现"><a href="#卷积前向的caffe实现" class="headerlink" title="卷积前向的caffe实现"></a>卷积前向的caffe实现</h3><p>Caffe中卷积的实现十分巧妙，详细可以参考一下这篇论文: <a href="https://hal.archives-ouvertes.fr/file/index/docid/112631/filename/p1038112283956.pdf" target="_blank" rel="external">https://hal.archives-ouvertes.fr/file/index/docid/112631/filename/p1038112283956.pdf</a></p>
<p>下面是一张论文中的图片，看这张图片可以很清楚理解。从图中可以看出，卷积之前将输入的多个矩阵和多个卷积核先展开再组合成2个大的矩阵，用展开后的矩阵相乘。</p>
<p><img src="/images/cnn/8.png" alt=""></p>
<p>假设我们一次训练16张图片(即batch_size为16)。通过之前的推导，我们知道该层的输入为20个 $12\times 12$ 的特征图，所以bottom的维度 $16\times 20\times 12\times 12$ ，则该层的输出top的维度为 $16\times 50 \times 8\times 8$ 。</p>
<h1 id="后向传播"><a href="#后向传播" class="headerlink" title="后向传播"></a>后向传播</h1><h2 id="反向梯度"><a href="#反向梯度" class="headerlink" title="反向梯度"></a>反向梯度</h2><p>在BP神经网络中，误差信号反向传递子过程比较复杂，它是基于 <code>Widrow-Hoff</code> 学习规则的。假设输出层的所有结果为，误差函数如下<br>$$E\left( w,b \right) =\frac{1}{2}\sum_{j=0}^{n-1}{\left( d_j-y_j \right) ^2}$$</p>
<p>而BP神经网络的主要目的是反复修正权值和阀值，使得误差函数值达到最小。<code>Widrow-Hoff</code> 学习规则是通过沿着相对误差平方和的最速下降方向，连续调整网络的权值和阀值，根据梯度下降法，权值矢量的修正正比于当前位置上 $E(w,b)$ 的梯度，对于第 $j$ 个输出节点有<br>$$\varDelta w\left( i,j \right) =-\eta \frac{\partial E\left( w,b \right)}{\partial w\left( i,j \right)}$$<br>假设我们选择激活函数：<br>$$f\left( x \right) =\frac{A}{1+e^{-\frac{x}{B}}}$$<br>对其进行求导：<br>$$<br>f’\left( x \right) =\frac{Ae^{-\frac{x}{B}}}{B\left( 1+e^{-\frac{x}{B}} \right) ^2}<br>$$<br>$$<br>=\frac{1}{AB}\cdot \frac{A}{1+e^{-\frac{x}{B}}}\cdot \left( A-\frac{A}{1+e^{-\frac{x}{B}}} \right)<br>$$<br>$$<br>=\frac{f\left( x \right) \left[ A-f\left( x \right) \right]}{AB}<br>$$<br>那么接下来针对 $w_{i,j}$</p>
<p>$$ \frac{\partial E\left( w,b \right)}{\partial w_{ij}}=\frac{1}{\partial w_{ij}}\cdot \frac{1}{2}\sum_{j=0}^{n-1}{\left( d_j-y_j \right) ^2} $$</p>
<p>$$<br>=\left( d_j-y_j \right) \cdot \frac{\partial d_j}{\partial w_{ij}}<br>$$</p>
<p>$$<br>=\left( d_j-y_j \right) \cdot f’\left( S_j \right) \frac{\partial S_j}{\partial w_{ij}}<br>$$</p>
<p>$$<br>=\left( d_j-y_j \right) \frac{f\left( S_j \right) \left[ A-f\left( S_j \right) \right]}{AB}<br>$$</p>
<p>$$<br>=\left( d_j-y_j \right) \frac{f\left( S_j \right) \left[ A-f\left( S_j \right) \right]}{AB}\cdot x_i<br>$$</p>
<p>$$=\delta_{ij}\cdot x_j$$</p>
<p>其中有</p>
<p>$$\delta_{ij}=\left( d_j-y_j \right) \frac{f\left( S_j \right) \left[ A-f\left( S_j \right) \right]}{AB} $$</p>
<p>同样，对于 $b_j$<br>$$<br>\frac{\partial E\left( w,b \right)}{\partial b_j}=\delta_{ij}<br>$$</p>
<p>这就是著名的 $\delta$   学习规则，通过改变神经元之间的连接权值来减少系统实际输出和期望输出的误差，这个规则又叫做<code>Widrow-Hoff</code>学习规则或者纠错学习规则。</p>
<p>上面是对隐含层和输出层之间的权值和输出层的阀值计算调整量，而针对输入层和隐含层和隐含层的阀值调整量的计算更为复杂。假设是输入层第 $k$ 个节点和隐含层第 $i$ 个节点之间的权值，那么有</p>
<p>$$<br>\frac{\partial E\left( w,b \right)}{\partial w_{ki}}=\frac{1}{\partial w_{ki}}\cdot \frac{1}{2}\sum_{j=0}^{n-1}{\left( d_j-y_j \right) ^2}<br>$$<br>$$<br>=\sum_{j=0}^{n-1}{\left( d_j-y_j \right) \cdot f’\left( S_j \right) \cdot \frac{\partial S_j}{\partial w_{kj}}}<br>$$<br>$$<br>=\sum_{j=0}^{n-1}{\left( d_j-y_j \right) \cdot f’\left( S_j \right) \cdot \frac{\partial S_j}{\partial x_i}\cdot \frac{\partial x_i}{\partial S_i}\cdot \frac{\partial S_j}{\partial w_{kj}}}<br>$$<br>$$<br>=\sum_{j=0}^{n-1}{\delta_{ij}\cdot w_{ij}\cdot \frac{f\left( S_j \right) \left[ A-f\left( S_j \right) \right]}{AB}}\cdot x_k<br>$$<br>$$<br>=x_k\cdot \sum_{j=0}^{n-1}{\delta_{ij}\cdot w_{ij}\cdot \frac{f\left( S_j \right) \left[ A-f\left( S_j \right) \right]}{AB}}<br>$$<br>$$<br>=\delta_{ki}\cdot x_k<br>$$<br> 其中有<br> $$<br>\delta_{ki}=\sum_{j=0}^{n-1}{\delta_{ij}\cdot w_{ij}\cdot \frac{f\left( S_j \right) \left[ A-f\left( S_j \right) \right]}{AB}}<br>$$</p>
<h2 id="梯度下降更新"><a href="#梯度下降更新" class="headerlink" title="梯度下降更新"></a>梯度下降更新</h2><p>有了上述公式，根据梯度下降法，那么对于隐含层和输出层之间的权值和阀值调整如下<br>$$<br>w_{ij}=w_{ij}-\eta_1\frac{\partial E\left( w,b \right)}{\partial w_{ij}}=w_{ij}-\eta_1\delta_{ij}\cdot x_i<br>$$</p>
<p>$$<br>b_j=b_j-\eta_2\frac{\partial E\left( w,b \right)}{\partial b_j}=b_j-\eta_2\delta_{ij}<br>$$<br>  而对于输入层和隐含层之间的权值和阀值调整同样有</p>
<p>  $$w_{ki}=w_{ki}-\eta_1\frac{\partial E\left( w,b \right)}{\partial w_{ki}}=w_{ki}-\eta_1\delta_{ki}\cdot x_k$$</p>
<p>$$b_i=b_i-\eta_2\frac{\partial E\left( w,b \right)}{\partial b_i}=b_i-\eta_2\delta_{ki}$$</p>
<h2 id="bp的缺陷"><a href="#bp的缺陷" class="headerlink" title="bp的缺陷"></a>bp的缺陷</h2><ol>
<li>容易形成局部极小值而得不到全局最优值。BP神经网络中极小值比较多，所以很容易陷入局部极小值，这就要求对初始权值和阀值有要求，要使得初始权值和阀值随机性足够好，可以多次随机来实现。</li>
<li>训练次数多使得学习效率低，收敛速度慢。</li>
<li>隐含层的选取缺乏理论的指导。</li>
<li>训练时学习新样本有遗忘旧样本的趋势。<h2 id="卷积的后向传播"><a href="#卷积的后向传播" class="headerlink" title="卷积的后向传播"></a>卷积的后向传播</h2>在反向传播过程中，若第x层的a节点通过权值W对x+1层的b节点有贡献，则在反向传播过程中，梯度通过权值W从b节点传播回a节点。不管下面的公式推导，还是后面的卷积神经网络，在反向传播的过程中，都是遵循这样的一个规律。</li>
</ol>
<p>卷积层的反向传播过程也是如此，我们只需要找出卷积层L中的每个单元和L+1层中的哪些单元相关联即可。我们还用此的图片举例子。<br><img src="/images/cnn/7.png" alt=""><br>在上图中，我们的矩阵A11通过权重B11与C11关联。而A12与2个矩阵C中2个元素相关联，分别是通过权重B12和C11关联，和通过权重B11和C12相关联。矩阵A中其他元素也类似。</p>
<p>那么，我们有没有简单的方法来实现这样的关联呢。答案是有的。可以通过将卷积核旋转180度，再与扩充后的梯度矩阵进行卷积。扩充的过程如下：如果卷积核为 $k\times k$ ，待卷积矩阵为 $n\times n$ ，需要以$n\times n$ 原矩阵为中心扩展到 $(n+2(k-1))\times (n+2(k-1))$ 。具体过程如下：<br>假设D为反向传播到卷积层的梯度矩阵，则D应该与矩阵C的大小相等，在这里为3*3。我们首先需要将它扩充到 $(3+2\times(2-1))\times (3+2\times(2-1)) = 5\times 5$ 大小的矩阵，<br><img src="/images/cnn/9.png" alt=""><br>同时将卷积核B旋转180度：<br><img src="/images/cnn/10.png" alt=""><br>将旋转后的卷积核与扩充后的梯度矩阵进行卷积：<br><img src="/images/cnn/11.png" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;  神经网络算法领域最初是被对生物神经系统建模这一目标启发，但随后与其分道扬镳，成为一个工程问题，并在机器学习领域取得良好效果。然而，讨论将还是从对生物系统的一个高层次的简略描述开始，因为神经网络毕竟是从这里得到了启发.&lt;br&gt;
    
    </summary>
    
      <category term="卷积深度网络" scheme="http://yoursite.com/categories/%E5%8D%B7%E7%A7%AF%E6%B7%B1%E5%BA%A6%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="卷积" scheme="http://yoursite.com/tags/%E5%8D%B7%E7%A7%AF/"/>
    
  </entry>
  
  <entry>
    <title>使用hexo快速搭建github pages博客</title>
    <link href="http://yoursite.com/2016/11/01/%E4%BD%BF%E7%94%A8hexo%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAgit%E5%8D%9A%E5%AE%A2/"/>
    <id>http://yoursite.com/2016/11/01/使用hexo快速搭建git博客/</id>
    <published>2016-11-01T15:40:13.000Z</published>
    <updated>2016-11-22T12:47:09.063Z</updated>
    
    <content type="html"><![CDATA[<h2 id="github-pages简介"><a href="#github-pages简介" class="headerlink" title=" github pages简介"></a> github pages简介</h2><p><img src="/images/gitblog/githubpages.png" alt=""></p>
<p>Github Pages 是 github 公司提供的免费的静态网站托管服务，用起来方便而且功能强大，不仅没有空间限制，还可以绑定自己的域名。在 <a href="https://pages.github.com/" target="_blank" rel="external">https://pages.github.com/</a> 首页上可以看到很多用 Github Pages 托管的网站，很漂亮。另外很多非常著名的公司和项目也都用这种方式来搭建网站，如微软和 twitter 的网站，还有 谷歌的 Material Design 图标 网站。<br><a id="more"></a></p>
<h2 id="node-js之hexo"><a href="#node-js之hexo" class="headerlink" title=" node.js之hexo"></a> node.js之hexo</h2><p>Node.js®是一个基于Chrome V8 引擎的 JavaScript 运行时。 Node.js 使用高效、轻量级的事件驱动、非阻塞 I/O 模型。Node.js 之生态系统是目前最大的开源包管理系统。</p>
<h2 id="hexo"><a href="#hexo" class="headerlink" title="hexo"></a>hexo</h2><p><img src="/images/gitblog/hexo.png" alt=""><br>Hexo 是高效的静态站点生成框架，她基于 Node.js。 通过 Hexo 你可以轻松地使用 Markdown 编写文章，除了 Markdown 本身的语法之外，还可以使用 Hexo 提供的 标签插件 来快速的插入特定形式的内容。在这篇文章中，假定你已经成功安装了 Hexo，并使用 Hexo 提供的命令创建了一个站点。</p>
<p>hexo出自台湾大学生tommy351之手，是一个基于Node.js的静态博客程序，其编译上百篇文字只需要几秒。hexo生成的静态网页可以直接放到GitHub Pages，BAE，SAE等平台上</p>
<h2 id="hexo之NexT主题"><a href="#hexo之NexT主题" class="headerlink" title=" hexo之NexT主题"></a> hexo之NexT主题</h2><p> 一个很好的基于hexo的主题，在NexT主题里有 scheme小主题的概念，非常棒，简约风格。<br> <img src="/images/gitblog/next.png" alt=""></p>
<h2 id="搭建博客系统"><a href="#搭建博客系统" class="headerlink" title=" 搭建博客系统"></a> 搭建博客系统</h2><p> 首先下载安装node.js <a href="https://nodejs.org/zh-cn/" target="_blank" rel="external">https://nodejs.org/zh-cn/</a></p>
<p>  下载之后打开node.js command prompt<br>  开始下载hexo<br>  运行如下的命令</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">$ npm install hexo-cli -g</div><div class="line">$ hexo init blog</div><div class="line">$ cd blog</div><div class="line">$ npm install</div><div class="line">$ hexo server</div><div class="line"></div><div class="line">#安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。</div><div class="line"></div><div class="line">#新建完成后，指定文件夹的目录如下</div><div class="line">.</div><div class="line">├── _config.yml</div><div class="line">├── package.json</div><div class="line">├── scaffolds</div><div class="line">├── scripts</div><div class="line">├── source</div><div class="line">|      ├── _drafts</div><div class="line">|      └── _posts</div><div class="line">└── themes</div></pre></td></tr></table></figure>
<p>  这时候使用<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo s</div></pre></td></tr></table></figure></p>
<p>  就可以打开 localhost: 4000进行访问看到hexo的landspace 就成功了</p>
<p>note：<br><code>如果你的安装了福新阅读器等一些占用4000端口的程序。就会加载不出来。</code></p>
<p>可以更改端口：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hexo s -p 3600</div></pre></td></tr></table></figure>
<p>安装成功之后可以绑定自己的gitHub.<br>后面的NexT主题安装部分详细见：</p>
<p><a href="http://theme-next.iissnan.com/" target="_blank" rel="external">http://theme-next.iissnan.com/</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;github-pages简介&quot;&gt;&lt;a href=&quot;#github-pages简介&quot; class=&quot;headerlink&quot; title=&quot; github pages简介&quot;&gt;&lt;/a&gt; github pages简介&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/images/gitblog/githubpages.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;Github Pages 是 github 公司提供的免费的静态网站托管服务，用起来方便而且功能强大，不仅没有空间限制，还可以绑定自己的域名。在 &lt;a href=&quot;https://pages.github.com/&quot;&gt;https://pages.github.com/&lt;/a&gt; 首页上可以看到很多用 Github Pages 托管的网站，很漂亮。另外很多非常著名的公司和项目也都用这种方式来搭建网站，如微软和 twitter 的网站，还有 谷歌的 Material Design 图标 网站。&lt;br&gt;
    
    </summary>
    
      <category term="环境搭建" scheme="http://yoursite.com/categories/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="git" scheme="http://yoursite.com/tags/git/"/>
    
      <category term="hexo" scheme="http://yoursite.com/tags/hexo/"/>
    
  </entry>
  
</feed>
